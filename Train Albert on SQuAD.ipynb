{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ALBERT for Question Answering - SQuAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updates:\n",
    "\n",
    "Things implemented:\n",
    "- Data Loading\n",
    "- Model\n",
    "- Learner\n",
    "- Prediction on new data\n",
    "- Optimizer selection\n",
    "- Segment IDs\n",
    "- F1 Score\n",
    "- Checkpoints\n",
    "- Use a more powerful machine to train\n",
    "\n",
    "TODO:\n",
    "- Consider using the sliding window approach for long sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:17.087618Z",
     "start_time": "2020-01-23T18:19:16.176376Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src import *\n",
    "from transformers import AutoTokenizer, AlbertForQuestionAnswering\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "import collections\n",
    "from tqdm import tqdm, trange\n",
    "from datetime import datetime\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig()\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:17.093885Z",
     "start_time": "2020-01-23T18:19:17.089365Z"
    }
   },
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    data_path = Path(\"../data/SQuAD/1.1\"), # replace with the directory containing the parsed csv files\n",
    "    output_dir = Path(\"./checkpoints\"), # for storing model weights between epochs\n",
    "    task = \"SQuAD\",\n",
    "    testing=False,\n",
    "    seed = 2020,\n",
    "    model = 'albert-base-v2',\n",
    "    max_lr=5e-5,\n",
    "    optimizer=\"lamb\", # choose between 'adam' or 'lamb'\n",
    "    epochs=2,\n",
    "    use_fp16=False,\n",
    "    recreate_ds=False,\n",
    "    bs=16, \n",
    "    effective_bs=16, # set this different from bs to determine gradient accumulation steps (i.e. effective_bs/bs)\n",
    "    max_seq_len=512,\n",
    "    start_tok = \"[CLS]\",\n",
    "    end_tok = \"[SEP]\",\n",
    "    sep_tok = \"[SEP]\",\n",
    "    unk_tok_idx=1,\n",
    "    sep_idx=3,\n",
    "    pad_idx=0,\n",
    "    feat_cols = [\"paragraph\",\"question\"],\n",
    "    label_cols = \"idxs\",\n",
    "    adjustment = 1,\n",
    "    save_checkpoint = True,\n",
    "    load_checkpoint=None#\"albert-base-v2-accuracy-0.72-epoch-0-2020-01-24 18:54:15.308899\"\n",
    ")\n",
    "\n",
    "config.model_name = re.findall(r\"(.+?)-\",config.model)[0]\n",
    "\n",
    "# set optimizer\n",
    "assert config.optimizer.lower() in [\"adam\",\"lamb\"], f\"invalid optimizer in config {config.optimizer}\"\n",
    "config.opt_func = lamb_opt() if config.optimizer.lower() == \"lamb\" else adam_opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:17.107256Z",
     "start_time": "2020-01-23T18:19:17.095807Z"
    }
   },
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def remove_max_sl(df):\n",
    "    init_len = len(df)\n",
    "    df = df[df.seq_len < config.max_seq_len-2]\n",
    "    new_len = len(df)\n",
    "    print(f\"dropping {init_len - new_len} out of {init_len} questions\")\n",
    "    return df\n",
    "\n",
    "def str2tensor(s):\n",
    "    indices = re.findall(\"\\d+\",s)\n",
    "    return torch.tensor([int(indices[0]), int(indices[1])], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:17.808887Z",
     "start_time": "2020-01-23T18:19:17.109008Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(config.data_path/f\"train_{config.model_name}.csv\")\n",
    "valid = pd.read_csv(config.data_path/f\"val_{config.model_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:17.850094Z",
     "start_time": "2020-01-23T18:19:17.810263Z"
    }
   },
   "outputs": [],
   "source": [
    "# randomizing the order of training data\n",
    "train = train.sample(frac=1,random_state = config.seed).reset_index(drop=True)\n",
    "valid = valid.sample(frac=1, random_state = config.seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:17.853831Z",
     "start_time": "2020-01-23T18:19:17.851403Z"
    }
   },
   "outputs": [],
   "source": [
    "# reduce df sizes if testing\n",
    "if config.testing:\n",
    "    train = train[:1000]\n",
    "    valid = valid[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:17.879760Z",
     "start_time": "2020-01-23T18:19:17.855198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping 136 out of 87599 questions\n",
      "dropping 184 out of 34726 questions\n"
     ]
    }
   ],
   "source": [
    "train, valid = remove_max_sl(train), remove_max_sl(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:17.891191Z",
     "start_time": "2020-01-23T18:19:17.881214Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>answer</th>\n",
       "      <th>idxs</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>About how many million square feet of office s...</td>\n",
       "      <td>Many of the world's largest media conglomerate...</td>\n",
       "      <td>['▁400']</td>\n",
       "      <td>[57, 58]</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On what date was George York executed?</td>\n",
       "      <td>The last use of the firing squad between 1608 ...</td>\n",
       "      <td>['▁june', '▁22', ',', '▁1965']</td>\n",
       "      <td>[59, 63]</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How did Wallace claim that patterns in the dis...</td>\n",
       "      <td>An 1855 paper on the \"introduction\" of species...</td>\n",
       "      <td>['▁if', '▁every', '▁new', '▁species', '▁always...</td>\n",
       "      <td>[34, 50]</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did Gaddafi's decisions in the oil industr...</td>\n",
       "      <td>With crude oil as the country's primary export...</td>\n",
       "      <td>['▁in', '▁1970', ',', '▁other', '▁op', 'ec', '...</td>\n",
       "      <td>[65, 87]</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What word describes an aortic valve with two r...</td>\n",
       "      <td>Schwarzenegger was born with a bicuspid aortic...</td>\n",
       "      <td>['▁b', 'icus', 'pid']</td>\n",
       "      <td>[7, 10]</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  About how many million square feet of office s...   \n",
       "1             On what date was George York executed?   \n",
       "2  How did Wallace claim that patterns in the dis...   \n",
       "3  How did Gaddafi's decisions in the oil industr...   \n",
       "4  What word describes an aortic valve with two r...   \n",
       "\n",
       "                                           paragraph  \\\n",
       "0  Many of the world's largest media conglomerate...   \n",
       "1  The last use of the firing squad between 1608 ...   \n",
       "2  An 1855 paper on the \"introduction\" of species...   \n",
       "3  With crude oil as the country's primary export...   \n",
       "4  Schwarzenegger was born with a bicuspid aortic...   \n",
       "\n",
       "                                              answer      idxs  seq_len  \n",
       "0                                           ['▁400']  [57, 58]       99  \n",
       "1                     ['▁june', '▁22', ',', '▁1965']  [59, 63]      147  \n",
       "2  ['▁if', '▁every', '▁new', '▁species', '▁always...  [34, 50]      237  \n",
       "3  ['▁in', '▁1970', ',', '▁other', '▁op', 'ec', '...  [65, 87]      149  \n",
       "4                              ['▁b', 'icus', 'pid']   [7, 10]      132  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:17.901784Z",
     "start_time": "2020-01-23T18:19:17.894195Z"
    }
   },
   "outputs": [],
   "source": [
    "class TokenizerProcessor(Processor):\n",
    "    def __init__(self, tok_func, max_sl, start_tok, end_tok, pre_rules=None,post_rules=None):\n",
    "        self.tok_func,self.max_sl = tok_func,max_sl\n",
    "        self.pre_rules,self.post_rules=pre_rules,post_rules\n",
    "        self.start_tok, self.end_tok = start_tok, end_tok\n",
    "\n",
    "    def proc1(self, x): return [self.start_tok] + self.tok_func(x)[:self.max_sl-2] + [self.end_tok]\n",
    "    \n",
    "    def __call__(self, items): return tqdm([self.proc1(x) for x in items])\n",
    "\n",
    "class NumericalizeProcessor(Processor):\n",
    "    \"\"\"\n",
    "    only works with an existing vocab at the moment and min_freq is not accounted for\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab:dict, unk_tok_idx:int, min_freq=2): \n",
    "        self.vocab, self.unk_tok_idx, self.min_freq = vocab, unk_tok_idx, min_freq\n",
    "    \n",
    "    def proc1(self, x): return [self.vocab[i] if i in self.vocab else self.unk_tok_idx for i in x]\n",
    "    \n",
    "    def __call__(self, items): \n",
    "        if getattr(self, 'otoi', None) is None:\n",
    "            self.otoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.vocab)})\n",
    "        return tqdm([self.proc1(x) for x in items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:18.646976Z",
     "start_time": "2020-01-23T18:19:17.903653Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/albert-base-v2-spiece.model HTTP/1.1\" 200 0\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-spiece.model from cache at /home/ubuntu/.cache/torch/transformers/dd1588b85b6fdce1320e224d29ad062e97588e17326b9d05a0b29ee84b8f5f93.c81d4deb77aec08ce575b7a39a989a79dd54f321bfb82c2b54dd35f52f8182cf\n"
     ]
    }
   ],
   "source": [
    "tok = AutoTokenizer.from_pretrained(config.model)\n",
    "proc_tok = TokenizerProcessor(tok.tokenize, config.max_seq_len, config.start_tok, config.end_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:18.678100Z",
     "start_time": "2020-01-23T18:19:18.648432Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab = {tok.convert_ids_to_tokens(i):i for i in range(tok.vocab_size)}\n",
    "proc_num = NumericalizeProcessor(vocab, unk_tok_idx=config.unk_tok_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:18.689917Z",
     "start_time": "2020-01-23T18:19:18.679584Z"
    }
   },
   "outputs": [],
   "source": [
    "class QALabelProcessor(Processor):\n",
    "    def __init__(self, parse_func = noop, adjustment = 1):\n",
    "        self.parse_func = parse_func\n",
    "        self.adjustment = adjustment\n",
    "    def proc1(self, item): return self.parse_func(item) + self.adjustment\n",
    "    def __call__(self, items): return [self.proc1(item) for item in items]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:18.697130Z",
     "start_time": "2020-01-23T18:19:18.691080Z"
    }
   },
   "outputs": [],
   "source": [
    "proc_qa = QALabelProcessor(str2tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:18.703553Z",
     "start_time": "2020-01-23T18:19:18.698405Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextList(ItemList):      \n",
    "    @classmethod  \n",
    "    def from_df(cls, df, feat_cols, label_col, sep_tok, test=False):\n",
    "        feat_cols = listify(feat_cols)\n",
    "        x = df[feat_cols[0]]\n",
    "        for i in range(1,len(feat_cols)):\n",
    "            x += f\" {sep_tok} \" + df[feat_cols[i]]\n",
    "        labels = cls(df[label_col]) if not test else cls([0 for _ in len(df)])\n",
    "        return cls(x,labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:23.907910Z",
     "start_time": "2020-01-23T18:19:18.704895Z"
    }
   },
   "outputs": [],
   "source": [
    "if (not (config.data_path/\"squad_data_trn.pkl\").exists()) or config.recreate_ds or config.testing:\n",
    "    il_train = TextList.from_df(train,config.feat_cols,config.label_cols,config.sep_tok)\n",
    "    il_valid = TextList.from_df(valid,config.feat_cols,config.label_cols,config.sep_tok)\n",
    "\n",
    "    ll_valid = LabeledData(il_valid,il_valid.labels,proc_x = [proc_tok,proc_num], proc_y=[proc_qa])\n",
    "    ll_train = LabeledData(il_train,il_train.labels,proc_x = [proc_tok,proc_num], proc_y=[proc_qa])\n",
    "\n",
    "    # saving/loading presaved data\n",
    "    if not config.testing:\n",
    "        # save an object\n",
    "        pickle.dump(ll_train, open( config.data_path/\"squad_data_trn.pkl\", \"wb\" ) )\n",
    "        pickle.dump(ll_valid, open( config.data_path/\"squad_data_val.pkl\", \"wb\" ) )\n",
    "else:\n",
    "    # load an object\n",
    "    ll_train = pickle.load( open( config.data_path/\"squad_data_trn.pkl\", \"rb\" ) )\n",
    "    ll_valid = pickle.load( open( config.data_path/\"squad_data_val.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:23.913193Z",
     "start_time": "2020-01-23T18:19:23.909255Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Sampler\n",
    "\n",
    "class SortSampler(Sampler):\n",
    "    def __init__(self, data_source, key): self.data_source,self.key = data_source,key\n",
    "    def __len__(self): return len(self.data_source)\n",
    "    def __iter__(self):\n",
    "        return iter(sorted(list(range(len(self.data_source))), key=self.key, reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:23.935217Z",
     "start_time": "2020-01-23T18:19:23.914489Z"
    }
   },
   "outputs": [],
   "source": [
    "class SortishSampler(Sampler):\n",
    "    def __init__(self, data_source, key, bs):\n",
    "        self.data_source,self.key,self.bs = data_source,key,bs\n",
    "\n",
    "    def __len__(self) -> int: return len(self.data_source)\n",
    "\n",
    "    def __iter__(self):\n",
    "        idxs = torch.randperm(len(self.data_source))\n",
    "        megabatches = [idxs[i:i+self.bs*50] for i in range(0, len(idxs), self.bs*50)]\n",
    "        sorted_idx = torch.cat([tensor(sorted(s, key=self.key, reverse=True)) for s in megabatches])\n",
    "        batches = [sorted_idx[i:i+self.bs] for i in range(0, len(sorted_idx), self.bs)]\n",
    "        max_idx = torch.argmax(tensor([self.key(ck[0]) for ck in batches]))  # find the chunk with the largest key,\n",
    "        batches[0],batches[max_idx] = batches[max_idx],batches[0]            # then make sure it goes first.\n",
    "        batch_idxs = torch.randperm(len(batches)-2)\n",
    "        sorted_idx = torch.cat([batches[i+1] for i in batch_idxs]) if len(batches) > 1 else LongTensor([])\n",
    "        sorted_idx = torch.cat([batches[0], sorted_idx, batches[-1]])\n",
    "        return iter(sorted_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:23.944689Z",
     "start_time": "2020-01-23T18:19:23.936421Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_collate_qa(samples, pad_idx=config.pad_idx, pad_first=False):\n",
    "    max_len = max([len(s[0]) for s in samples])\n",
    "    res = torch.zeros(len(samples), max_len).long() + pad_idx\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: res[i, -len(s[0]):] = torch.LongTensor(s[0])\n",
    "        else:         res[i, :len(s[0]) ] = torch.LongTensor(s[0])\n",
    "    return res, torch.cat([s[1].unsqueeze(0) for s in samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:23.954103Z",
     "start_time": "2020-01-23T18:19:23.945863Z"
    }
   },
   "outputs": [],
   "source": [
    "train_sampler = SortishSampler(ll_train.x, key=lambda t: len(ll_train[int(t)][0]), bs=config.bs)\n",
    "train_dl = DataLoader(ll_train, batch_size=config.bs, sampler=train_sampler, collate_fn=pad_collate_qa)\n",
    "\n",
    "valid_sampler = SortSampler(ll_valid.x, key=lambda t: len(ll_valid[int(t)][0]))\n",
    "valid_dl = DataLoader(ll_valid, batch_size=config.bs, sampler=valid_sampler, collate_fn=pad_collate_qa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:35.758447Z",
     "start_time": "2020-01-23T18:19:35.756582Z"
    }
   },
   "outputs": [],
   "source": [
    "data = DataBunch(train_dl,valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.sep_idx = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_segments(x,sep_idx=config.sep_idx):\n",
    "    res = x.new_zeros(x.size())\n",
    "    for row_idx, row in enumerate(x):\n",
    "        in_seg_1 = False\n",
    "        for val_idx,val in enumerate(row):\n",
    "            if val == sep_idx:\n",
    "                in_seg_1 = True\n",
    "            if in_seg_1: \n",
    "                res[row_idx,val_idx] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:35.769996Z",
     "start_time": "2020-01-23T18:19:35.759647Z"
    }
   },
   "outputs": [],
   "source": [
    "weights = config.output_dir/config.load_checkpoint if config.load_checkpoint else config.model\n",
    "\n",
    "class CustomAlbertModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomAlbertModel,self).__init__()\n",
    "        self.bert = AlbertForQuestionAnswering.from_pretrained(weights)\n",
    "        self.bert.train()\n",
    "        \n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):       \n",
    "        token_type_ids = set_segments(input_ids)\n",
    "        outputs = self.bert(input_ids,token_type_ids=token_type_ids)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(learner,output_dir: Path):\n",
    "    def _create_dir(dirc):\n",
    "        if not os.path.exists(dirc): os.mkdir(dirc)\n",
    "    epoch = learner.epoch\n",
    "    metric = round(float(learner.qa_avg_stats.valid_stats.avg_stats[1]),2)\n",
    "    _create_dir(output_dir)\n",
    "    model_dir = f\"{config.model}-accuracy-{metric}-epoch-{epoch}-\" + str(datetime.now())\n",
    "    _create_dir(output_dir/model_dir)\n",
    "    learner.model.bert.save_pretrained(output_dir/model_dir)\n",
    "\n",
    "class SaveModelCallback(Callback):\n",
    "    def __init__(self,save_model_func,output_dir):\n",
    "        self.output_dir, self.save_model_func = output_dir,save_model_func\n",
    "    def after_epoch(self):\n",
    "        self.save_model_func(self, self.output_dir)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient accumulation\n",
    "class GradientAccumulation(Callback):\n",
    "    def __init__(self,bs,effective_bs):\n",
    "        self.bs, self.effective_bs = bs, effective_bs\n",
    "    def after_backward(self):\n",
    "        if self.n_iter*self.bs % self.effective_bs != 0: raise CancelBatchException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:35.775536Z",
     "start_time": "2020-01-23T18:19:35.771148Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining the loss function\n",
    "def cross_entropy_qa(input, target):\n",
    "    \"\"\"\n",
    "    Summing the cross entropy loss from the starting and ending indices. \n",
    "    \"\"\"\n",
    "    loss = torch.add(F.cross_entropy(input[0], target[:,0]) , F.cross_entropy(input[1], target[:,1]))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAAvgStats(AvgStats):\n",
    "    def accumulate(self, run):\n",
    "        bn = run.xb.shape[0]\n",
    "        self.tot_loss += run.loss * bn\n",
    "        self.count += bn\n",
    "        for i,m in enumerate(self.metrics):\n",
    "            self.tot_mets[i] += m(run.pred, run.yb, run.xb) * bn\n",
    "            \n",
    "class QAAvgStatsCallback(AvgStatsCallback):\n",
    "    def __init__(self, metrics):\n",
    "        self.train_stats,self.valid_stats = QAAvgStats(metrics,True),QAAvgStats(metrics,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:35.781695Z",
     "start_time": "2020-01-23T18:19:35.776758Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining the evaluation metrics based on squad evaluation method\n",
    "def acc_qa(input,target,xb):\n",
    "    \"\"\"\n",
    "    Taking the average between the accuracies of predicting the start and ending indices\n",
    "    \"\"\"\n",
    "    return (accuracy(input[0], target[:,0]) + accuracy(input[1], target[:,1]))/2\n",
    "\n",
    "def exact_match(input,target,xb):\n",
    "    def _acc(out, yb): return (torch.argmax(out, dim=1)==yb).float()\n",
    "    return (_acc(input[0], target[:,0]) + _acc(input[1], target[:,1]) == 2).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:35.781695Z",
     "start_time": "2020-01-23T18:19:35.776758Z"
    }
   },
   "outputs": [],
   "source": [
    "def f1_score(input,target,xb):\n",
    "    \"\"\"\n",
    "    based on the official evaluation script:\n",
    "    https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/\n",
    "    \"\"\"\n",
    "    pred_starts,pred_ends = [torch.argmax(out, dim=1) for out in input]\n",
    "    gold_starts,gold_ends = target[:,0], target[:,1]\n",
    "    \n",
    "    def _get_toks(idx,start,end):\n",
    "        if start == end: end += 1\n",
    "        return xb[idx][start:end]\n",
    "    \n",
    "    def _score1(pred_toks,gold_toks):\n",
    "        common = collections.Counter(gold_toks.tolist()) & collections.Counter(pred_toks.tolist())\n",
    "        num_same = sum(common.values())\n",
    "        if num_same == 0: \n",
    "            return 0\n",
    "        precision = 1.0 * num_same / len(pred_toks)\n",
    "        recall = 1.0 * num_same / len(gold_toks)\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "        return f1\n",
    "    \n",
    "    pred_toks = [_get_toks(i,start,end) for i,(start,end) in enumerate(zip(pred_starts,pred_ends))]\n",
    "    gold_toks = [_get_toks(i,start,end) for i,(start,end) in enumerate(zip(gold_starts,gold_ends))]\n",
    "    score = np.mean([_score1(pred,gold) for pred,gold in zip(pred_toks,gold_toks)])\n",
    "    return score             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:35.790610Z",
     "start_time": "2020-01-23T18:19:35.782858Z"
    }
   },
   "outputs": [],
   "source": [
    "cbfs = [partial(QAAvgStatsCallback,[acc_qa,exact_match,f1_score]),\n",
    "        CudaCallback,\n",
    "        ProgressCallback,\n",
    "        Recorder]\n",
    "\n",
    "if not config.testing and config.save_checkpoint: \n",
    "    cbfs.append(partial(SaveModelCallback,save_model,config.output_dir))\n",
    "    \n",
    "if config.effective_bs and config.bs != config.effective_bs:\n",
    "    cbfs.append(partial(GradientAccumulation,config.bs,config.effective_bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:36.732223Z",
     "start_time": "2020-01-23T18:19:35.791749Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/albert-base-v2-config.json HTTP/1.1\" 200 0\n",
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-config.json from cache at /home/ubuntu/.cache/torch/transformers/0bbb1531ce82f042a813219ffeed7a1fa1f44cd8f78a652c47fc5311e0d40231.ea38adf566af403b92e06f53ac1b443ebd324162fc74a90de95609963d429505\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"finetuning_task\": null,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/albert-base-v2-pytorch_model.bin HTTP/1.1\" 200 0\n",
      "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-pytorch_model.bin from cache at /home/ubuntu/.cache/torch/transformers/a175de1d3c60bba6e74bd034c02a34d909d9f36a0cf472b02301c8790ba44834.ab806923413c2af99835e13fdbb6014b24af86b0de8edc2d71ef5c646fc54f24\n",
      "INFO:transformers.modeling_utils:Weights of AlbertForQuestionAnswering not initialized from pretrained model: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "INFO:transformers.modeling_utils:Weights from pretrained model not used in AlbertForQuestionAnswering: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n"
     ]
    }
   ],
   "source": [
    "model = CustomAlbertModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:36.737967Z",
     "start_time": "2020-01-23T18:19:36.734260Z"
    }
   },
   "outputs": [],
   "source": [
    "def albert_splitter(m, g1=[],g2=[]):\n",
    "    if \"qa_outputs\" in list(dict(m.named_children()).keys()) :\n",
    "        g2+= m.qa_outputs.parameters()\n",
    "        pass\n",
    "    elif isinstance(m,torch.nn.modules.normalization.LayerNorm):\n",
    "        g2+= m.parameters()\n",
    "    elif hasattr(m, 'weight'): \n",
    "        g1+= m.parameters()\n",
    "    for ll in m.children(): albert_splitter(ll, g1, g2)\n",
    "    return g1,g2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:36.755509Z",
     "start_time": "2020-01-23T18:19:36.739129Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/fastai/course-v3/blob/master/nbs/dl2/11_train_imagenette.ipynb\n",
    "def create_phases(phases):\n",
    "    phases = listify(phases)\n",
    "    return phases + [1-sum(phases)]\n",
    "\n",
    "# https://github.com/fastai/course-v3/blob/master/nbs/dl2/11a_transfer_learning.ipynb\n",
    "def sched_1cycle(lrs, pct_start=0.3, mom_start=0.95, mom_mid=0.85, mom_end=0.95):\n",
    "    phases = create_phases(pct_start)\n",
    "    sched_lr  = [combine_scheds(phases, cos_1cycle_anneal(lr/10., lr, lr/1e5))\n",
    "                 for lr in lrs]\n",
    "    sched_mom = combine_scheds(phases, cos_1cycle_anneal(mom_start, mom_mid, mom_end))\n",
    "    return [ParamScheduler('lr', sched_lr),\n",
    "            ParamScheduler('mom', sched_mom)]\n",
    "\n",
    "disc_lr_sched = sched_1cycle([config.max_lr,1e-4], 0.5) # 3e-2 best with adam, 1e-3 for lamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:36.763669Z",
     "start_time": "2020-01-23T18:19:36.756591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21, 8]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the learning rate we apply here does not matter since we are scheduling \n",
    "learn = Learner(model, data, cross_entropy_qa,lr=config.max_lr,cb_funcs=cbfs,splitter=albert_splitter,opt_func=config.opt_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T19:49:29.929909Z",
     "start_time": "2020-01-23T18:19:36.764709Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='2', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc_qa</th>\n",
       "      <th>train_exact_match</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_acc_qa</th>\n",
       "      <th>valid_exact_match</th>\n",
       "      <th>valid_f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.986166</td>\n",
       "      <td>0.494579</td>\n",
       "      <td>0.345008</td>\n",
       "      <td>0.538306</td>\n",
       "      <td>2.292416</td>\n",
       "      <td>0.693381</td>\n",
       "      <td>0.556142</td>\n",
       "      <td>0.773515</td>\n",
       "      <td>2:13:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.129145</td>\n",
       "      <td>0.693185</td>\n",
       "      <td>0.554693</td>\n",
       "      <td>0.769716</td>\n",
       "      <td>2.144678</td>\n",
       "      <td>0.711909</td>\n",
       "      <td>0.581786</td>\n",
       "      <td>0.792053</td>\n",
       "      <td>2:15:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in checkpoints/albert-base-v2-accuracy-0.69-epoch-0-2020-01-28 17:39:38.207929/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in checkpoints/albert-base-v2-accuracy-0.69-epoch-0-2020-01-28 17:39:38.207929/pytorch_model.bin\n",
      "INFO:transformers.configuration_utils:Configuration saved in checkpoints/albert-base-v2-accuracy-0.71-epoch-1-2020-01-28 19:55:21.593928/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in checkpoints/albert-base-v2-accuracy-0.71-epoch-1-2020-01-28 19:55:21.593928/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "learn.fit(2,cbs=disc_lr_sched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='2', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc_qa</th>\n",
       "      <th>train_exact_match</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_acc_qa</th>\n",
       "      <th>valid_exact_match</th>\n",
       "      <th>valid_f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.944356</td>\n",
       "      <td>0.713589</td>\n",
       "      <td>0.579266</td>\n",
       "      <td>0.791034</td>\n",
       "      <td>2.180622</td>\n",
       "      <td>0.713229</td>\n",
       "      <td>0.585571</td>\n",
       "      <td>0.792867</td>\n",
       "      <td>2:15:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.799865</td>\n",
       "      <td>0.731735</td>\n",
       "      <td>0.600259</td>\n",
       "      <td>0.809088</td>\n",
       "      <td>2.125806</td>\n",
       "      <td>0.719215</td>\n",
       "      <td>0.590969</td>\n",
       "      <td>0.800733</td>\n",
       "      <td>2:15:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in checkpoints/albert-base-v2-accuracy-0.71-epoch-0-2020-01-28 22:10:57.359426/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in checkpoints/albert-base-v2-accuracy-0.71-epoch-0-2020-01-28 22:10:57.359426/pytorch_model.bin\n",
      "INFO:transformers.configuration_utils:Configuration saved in checkpoints/albert-base-v2-accuracy-0.72-epoch-1-2020-01-29 00:26:50.348875/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in checkpoints/albert-base-v2-accuracy-0.72-epoch-1-2020-01-29 00:26:50.348875/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "learn.fit(2,cbs=disc_lr_sched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually save and load model weights\n",
    "\n",
    "# save_model(learn,config.out_path)\n",
    "# learn.model.bert.from_pretrained(config.output_dir/'albert-base-v2-accuracy-0.72-epoch-3-2020-01-24 16:22:37.693825')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T20:10:04.511609Z",
     "start_time": "2020-01-23T20:10:04.499223Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_collate_x(samples, pad_idx=config.pad_idx, pad_first=False):\n",
    "    max_len = max([len(s[0]) for s in samples])\n",
    "    res = torch.zeros(len(samples), max_len).long() + pad_idx\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: res[i, -len(s[0]):] = torch.LongTensor(s[0])\n",
    "        else:         res[i, :len(s[0]) ] = torch.LongTensor(s[0])\n",
    "    return res\n",
    "\n",
    "def get_pred(text, model, tok):\n",
    "    # 0. Ensure the input is a list for batch processing\n",
    "    text = listify(text)\n",
    "    # 1. tokenize/encode the input text\n",
    "    input_ids = pad_collate_x([torch.tensor(tok.encode(t)).unsqueeze(0) for t in text])\n",
    "    if torch.cuda.is_available(): input_ids, model = input_ids.cuda(), model.cuda()\n",
    "    # 2. extract the logits vector for each item \n",
    "    logits = model(input_ids)\n",
    "    # 3. apply argmax to the logits so we have the probabilities of each item's start and end indices\n",
    "    starts,ends = [torch.argmax(out, dim=1) for out in logits]\n",
    "    \n",
    "    def _proc1(idx,start,end):\n",
    "        # function to process one item at a time\n",
    "        if start > end:\n",
    "            return \"unanswerable\"\n",
    "        elif start == end:\n",
    "            end += 1\n",
    "        pred = tok.convert_ids_to_tokens(input_ids[idx][start:end])\n",
    "        return tok.convert_tokens_to_string(pred)\n",
    "    return [_proc1(idx,start,end) for idx,(start,end) in enumerate(zip(starts,ends))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T20:10:04.806392Z",
     "start_time": "2020-01-23T20:10:04.702234Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thirty', 'storm', 'no.2 pencils']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tests with samples \n",
    "sample1 = \"[CLS] there have been thirty earthquakes in the past three days. [SEP] how many earthquakes have there been? [SEP]\"\n",
    "sample2 = \"[CLS] the storm took place yesterday from dawn to dusk [SEP] what took place??\"\n",
    "sample3 = \"[CLS] No.2 pencils are used a lot in schools. [SEP] what are used?\"\n",
    "get_pred([sample1,sample2,sample3], learn.model, tok)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (qa)",
   "language": "python",
   "name": "qa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
