{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ALBERT for Question Answering - SQuAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updates:\n",
    "\n",
    "Things implemented:\n",
    "- Data Loading\n",
    "- Model\n",
    "- Learner\n",
    "- Prediction on new data\n",
    "- Optimizer selection\n",
    "- Segment IDs\n",
    "- F1 Score\n",
    "- Checkpoints\n",
    "- Use a more powerful machine to train\n",
    "- Gradient Accumulation\n",
    "- Squad 2.0\n",
    "    - Multi Task Learning Changes\n",
    "\n",
    "TODO:\n",
    "- Consider using the sliding window approach for long sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:05.177108Z",
     "start_time": "2020-01-30T19:22:04.263754Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src import *\n",
    "from transformers import AutoTokenizer, AlbertModel,AlbertPreTrainedModel\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "import collections\n",
    "from tqdm import tqdm, trange\n",
    "from datetime import datetime\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:05.180470Z",
     "start_time": "2020-01-30T19:22:05.178530Z"
    }
   },
   "outputs": [],
   "source": [
    "# logging.basicConfig()\n",
    "# logger = logging.getLogger()\n",
    "# logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:05.195753Z",
     "start_time": "2020-01-30T19:22:05.181858Z"
    }
   },
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    data_path = Path(\"../data/SQuAD/2.0\"), # replace with the directory containing the parsed csv files\n",
    "    output_dir = Path(\"./checkpoints\"), # for storing model weights between epochs\n",
    "    task = \"SQuAD\",\n",
    "    squad_version = \"2.0\",\n",
    "    testing=True,\n",
    "    seed = 2020,\n",
    "    model = 'albert-base-v2',\n",
    "    max_lr=5e-5,\n",
    "    max_lr_last = 1e-4,\n",
    "    phases = .3,\n",
    "    optimizer=\"lamb\", # choose between 'adam' or 'lamb'\n",
    "    epochs=2,\n",
    "    use_fp16=False,\n",
    "    recreate_ds=False,\n",
    "    bs=8, \n",
    "    effective_bs=16, # set this different from bs to determine gradient accumulation steps (i.e. effective_bs/bs)\n",
    "    max_seq_len=512,\n",
    "    start_tok = \"[CLS]\",\n",
    "    end_tok = \"[SEP]\",\n",
    "    sep_tok = \"[SEP]\",\n",
    "    unk_tok_idx=1,\n",
    "    sep_idx=3,\n",
    "    pad_idx=0,\n",
    "    feat_cols = [\"question\",\"paragraph\"],\n",
    "    label_cols = [\"idxs\",\"is_impossible\"],\n",
    "    adjustment = 2,\n",
    "    save_checkpoint = True,\n",
    "    load_checkpoint=None#\"albert-base-v2-accuracy-0.72-epoch-0-2020-01-24 18:54:15.308899\"\n",
    ")\n",
    "\n",
    "config.model_name = re.findall(r\"(.+?)-\",config.model)[0]\n",
    "\n",
    "# set optimizer\n",
    "assert config.optimizer.lower() in [\"adam\",\"lamb\"], f\"invalid optimizer in config {config.optimizer}\"\n",
    "config.opt_func = lamb_opt() if config.optimizer.lower() == \"lamb\" else adam_opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:05.209887Z",
     "start_time": "2020-01-30T19:22:05.197357Z"
    }
   },
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def remove_max_sl(df):\n",
    "    init_len = len(df)\n",
    "    df = df[df.seq_len < config.max_seq_len-2]\n",
    "    new_len = len(df)\n",
    "    print(f\"dropping {init_len - new_len} out of {init_len} questions\")\n",
    "    return df\n",
    "\n",
    "def str2tensor(s):\n",
    "    indices = re.findall(\"-?\\d+\",s)\n",
    "    return torch.tensor([int(indices[0]), int(indices[1])], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:06.120236Z",
     "start_time": "2020-01-30T19:22:05.213470Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(config.data_path/f\"train_{config.squad_version}_{config.model_name}.csv\")\n",
    "valid = pd.read_csv(config.data_path/f\"val_{config.squad_version}_{config.model_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop_duplicates(inplace=True)\n",
    "valid.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:06.171349Z",
     "start_time": "2020-01-30T19:22:06.121334Z"
    }
   },
   "outputs": [],
   "source": [
    "# randomizing the order of training data\n",
    "train = train.sample(frac=1,random_state = config.seed).reset_index(drop=True)\n",
    "valid = valid.sample(frac=1, random_state = config.seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:06.175479Z",
     "start_time": "2020-01-30T19:22:06.172458Z"
    }
   },
   "outputs": [],
   "source": [
    "# reduce df sizes if testing\n",
    "if config.testing:\n",
    "    train = train[:int(len(train)/6)]\n",
    "    valid = valid[:int(len(valid)/6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:06.202213Z",
     "start_time": "2020-01-30T19:22:06.176544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping 29 out of 21715 questions\n",
      "dropping 15 out of 2715 questions\n"
     ]
    }
   ],
   "source": [
    "train, valid = remove_max_sl(train), remove_max_sl(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"idxs\"] = train.apply(lambda row: row[\"idxs\"] if not row[\"is_impossible\"] else '[-2, -2]',axis=1)\n",
    "valid[\"idxs\"] = valid.apply(lambda row: row[\"idxs\"] if not row[\"is_impossible\"] else '[-2, -2]',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:06.214823Z",
     "start_time": "2020-01-30T19:22:06.204482Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>answer</th>\n",
       "      <th>idxs</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>is_impossible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What president authorized the creation of the ...</td>\n",
       "      <td>The success of the British Commandos during Wo...</td>\n",
       "      <td>['▁franklin', '▁', 'd', '.', '▁roosevelt']</td>\n",
       "      <td>[27, 32]</td>\n",
       "      <td>236</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What places a greater emphasis on the acrobati...</td>\n",
       "      <td>According to FIG rules, only women compete in ...</td>\n",
       "      <td>['▁rhythmic', '▁gymnastics']</td>\n",
       "      <td>[-2, -2]</td>\n",
       "      <td>157</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How did the scheme measure desire?</td>\n",
       "      <td>From at least the late nineteenth century in E...</td>\n",
       "      <td>['▁on', '▁two', '▁independent', '▁10', '-', 'p...</td>\n",
       "      <td>[61, 68]</td>\n",
       "      <td>135</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What's Israel's financial and technology center?</td>\n",
       "      <td>Israel (/ˈɪzreɪəl/ or /ˈɪzriːəl/; Hebrew: יִשְ...</td>\n",
       "      <td>['▁tel', '▁aviv']</td>\n",
       "      <td>[235, 237]</td>\n",
       "      <td>275</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which museum houses the USA Midway aircraft ca...</td>\n",
       "      <td>Many popular museums, such as the San Diego Mu...</td>\n",
       "      <td>['▁san', '▁diego', '▁aircraft', '▁carrier', '▁...</td>\n",
       "      <td>[-2, -2]</td>\n",
       "      <td>155</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What president authorized the creation of the ...   \n",
       "1  What places a greater emphasis on the acrobati...   \n",
       "2                 How did the scheme measure desire?   \n",
       "3   What's Israel's financial and technology center?   \n",
       "4  Which museum houses the USA Midway aircraft ca...   \n",
       "\n",
       "                                           paragraph  \\\n",
       "0  The success of the British Commandos during Wo...   \n",
       "1  According to FIG rules, only women compete in ...   \n",
       "2  From at least the late nineteenth century in E...   \n",
       "3  Israel (/ˈɪzreɪəl/ or /ˈɪzriːəl/; Hebrew: יִשְ...   \n",
       "4  Many popular museums, such as the San Diego Mu...   \n",
       "\n",
       "                                              answer        idxs  seq_len  \\\n",
       "0         ['▁franklin', '▁', 'd', '.', '▁roosevelt']    [27, 32]      236   \n",
       "1                       ['▁rhythmic', '▁gymnastics']    [-2, -2]      157   \n",
       "2  ['▁on', '▁two', '▁independent', '▁10', '-', 'p...    [61, 68]      135   \n",
       "3                                  ['▁tel', '▁aviv']  [235, 237]      275   \n",
       "4  ['▁san', '▁diego', '▁aircraft', '▁carrier', '▁...    [-2, -2]      155   \n",
       "\n",
       "   is_impossible  \n",
       "0          False  \n",
       "1           True  \n",
       "2          False  \n",
       "3          False  \n",
       "4           True  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[\"idxs\"][0], ll_train.y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:06.223192Z",
     "start_time": "2020-01-30T19:22:06.216337Z"
    }
   },
   "outputs": [],
   "source": [
    "class TokenizerProcessor(Processor):\n",
    "    def __init__(self, tok_func, max_sl, start_tok, end_tok, pre_rules=None,post_rules=None):\n",
    "        self.tok_func,self.max_sl = tok_func,max_sl\n",
    "        self.pre_rules,self.post_rules=pre_rules,post_rules\n",
    "        self.start_tok, self.end_tok = start_tok, end_tok\n",
    "\n",
    "    def proc1(self, x): return [self.start_tok] + self.tok_func(x)[:self.max_sl-2] + [self.end_tok]\n",
    "    \n",
    "    def __call__(self, items): return tqdm([self.proc1(x) for x in items])\n",
    "\n",
    "class NumericalizeProcessor(Processor):\n",
    "    \"\"\"\n",
    "    only works with an existing vocab at the moment and min_freq is not accounted for\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab:dict, unk_tok_idx:int, min_freq=2): \n",
    "        self.vocab, self.unk_tok_idx, self.min_freq = vocab, unk_tok_idx, min_freq\n",
    "    \n",
    "    def proc1(self, x): return [self.vocab[i] if i in self.vocab else self.unk_tok_idx for i in x]\n",
    "    \n",
    "    def __call__(self, items): \n",
    "        if getattr(self, 'otoi', None) is None:\n",
    "            self.otoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.vocab)})\n",
    "        return tqdm([self.proc1(x) for x in items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:06.509552Z",
     "start_time": "2020-01-30T19:22:06.224274Z"
    }
   },
   "outputs": [],
   "source": [
    "tok = AutoTokenizer.from_pretrained(config.model)\n",
    "proc_tok = TokenizerProcessor(tok.tokenize, config.max_seq_len, config.start_tok, config.end_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:06.539859Z",
     "start_time": "2020-01-30T19:22:06.510611Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab = {tok.convert_ids_to_tokens(i):i for i in range(tok.vocab_size)}\n",
    "proc_num = NumericalizeProcessor(vocab, unk_tok_idx=config.unk_tok_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([-1,-1]) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:06.551413Z",
     "start_time": "2020-01-30T19:22:06.540912Z"
    }
   },
   "outputs": [],
   "source": [
    "class QALabelProcessor(Processor):\n",
    "    def __init__(self, parse_func = noop, adjustment = 2):\n",
    "        self.parse_func = parse_func\n",
    "        self.adjustment = adjustment\n",
    "        self.vocab=None\n",
    "        \n",
    "    def cat_proc1(self,item): return self.otoi[item]\n",
    "    def index_proc1(self, item): return self.parse_func(item) + self.adjustment\n",
    "    \n",
    "    def __call__(self, items): \n",
    "        if self.vocab is None:\n",
    "            self.vocab = uniqueify([o[1] for o in items])\n",
    "            self.otoi  = {v:k for k,v in enumerate(self.vocab)}\n",
    "        return [(self.index_proc1(item[0]),self.cat_proc1(item[1])) for item in items] # we want the \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:06.558336Z",
     "start_time": "2020-01-30T19:22:06.552470Z"
    }
   },
   "outputs": [],
   "source": [
    "proc_qa = QALabelProcessor(str2tensor,config.adjustment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:06.569643Z",
     "start_time": "2020-01-30T19:22:06.559384Z"
    }
   },
   "outputs": [],
   "source": [
    "class SquadTextList(ItemList):      \n",
    "    @classmethod  \n",
    "    def from_df(cls, df, feat_cols, label_cols, sep_tok, test=False):\n",
    "        feat_cols = listify(feat_cols)\n",
    "        x = df[feat_cols[0]]\n",
    "        for i in range(1,len(feat_cols)):\n",
    "            x += f\" {sep_tok} \" + df[feat_cols[i]]\n",
    "        labels = cls(df[label_cols].values) if not test else cls([[None,None] for _ in len(df)])\n",
    "        return cls(x,labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:07.440069Z",
     "start_time": "2020-01-30T19:22:06.572771Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2700/2700 [00:00<00:00, 19025.65it/s]\n",
      "100%|██████████| 2700/2700 [00:00<00:00, 179218.23it/s]\n",
      "100%|██████████| 21686/21686 [00:01<00:00, 17573.77it/s]\n",
      "100%|██████████| 21686/21686 [00:00<00:00, 188993.15it/s]\n"
     ]
    }
   ],
   "source": [
    "if (not (config.data_path/f\"squad_{config.squad_version}_data_trn.pkl\").exists()) or config.recreate_ds or config.testing:\n",
    "    il_train = SquadTextList.from_df(train,config.feat_cols,config.label_cols,config.sep_tok)\n",
    "    il_valid = SquadTextList.from_df(valid,config.feat_cols,config.label_cols,config.sep_tok)\n",
    "\n",
    "    ll_valid = LabeledData(il_valid,il_valid.labels,proc_x = [proc_tok,proc_num], proc_y=[proc_qa])\n",
    "    ll_train = LabeledData(il_train,il_train.labels,proc_x = [proc_tok,proc_num], proc_y=[proc_qa])\n",
    "\n",
    "    # saving/loading presaved data if not testing\n",
    "    if not config.testing:\n",
    "        # save an object\n",
    "        pickle.dump(ll_train, open( config.data_path/f\"squad_{config.squad_version}_data_trn.pkl\", \"wb\" ) )\n",
    "        pickle.dump(ll_valid, open( config.data_path/f\"squad_{config.squad_version}_data_val.pkl\", \"wb\" ) )\n",
    "else:\n",
    "    # load an object\n",
    "    ll_train = pickle.load( open( config.data_path/f\"squad_{config.squad_version}_data_trn.pkl\", \"rb\" ) )\n",
    "    ll_valid = pickle.load( open( config.data_path/f\"squad_{config.squad_version}_data_val.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:07.444719Z",
     "start_time": "2020-01-30T19:22:07.441157Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Sampler\n",
    "\n",
    "class SortSampler(Sampler):\n",
    "    def __init__(self, data_source, key): self.data_source,self.key = data_source,key\n",
    "    def __len__(self): return len(self.data_source)\n",
    "    def __iter__(self):\n",
    "        return iter(sorted(list(range(len(self.data_source))), key=self.key, reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:07.460307Z",
     "start_time": "2020-01-30T19:22:07.446008Z"
    }
   },
   "outputs": [],
   "source": [
    "class SortishSampler(Sampler):\n",
    "    def __init__(self, data_source, key, bs):\n",
    "        self.data_source,self.key,self.bs = data_source,key,bs\n",
    "\n",
    "    def __len__(self) -> int: return len(self.data_source)\n",
    "\n",
    "    def __iter__(self):\n",
    "        idxs = torch.randperm(len(self.data_source))\n",
    "        megabatches = [idxs[i:i+self.bs*50] for i in range(0, len(idxs), self.bs*50)]\n",
    "        sorted_idx = torch.cat([tensor(sorted(s, key=self.key, reverse=True)) for s in megabatches])\n",
    "        batches = [sorted_idx[i:i+self.bs] for i in range(0, len(sorted_idx), self.bs)]\n",
    "        max_idx = torch.argmax(tensor([self.key(ck[0]) for ck in batches]))  # find the chunk with the largest key,\n",
    "        batches[0],batches[max_idx] = batches[max_idx],batches[0]            # then make sure it goes first.\n",
    "        batch_idxs = torch.randperm(len(batches)-2)\n",
    "        sorted_idx = torch.cat([batches[i+1] for i in batch_idxs]) if len(batches) > 1 else LongTensor([])\n",
    "        sorted_idx = torch.cat([batches[0], sorted_idx, batches[-1]])\n",
    "        return iter(sorted_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:07.471935Z",
     "start_time": "2020-01-30T19:22:07.461508Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_collate_qa(samples, pad_idx=config.pad_idx, pad_first=False):\n",
    "    max_len = max([len(s[0]) for s in samples])\n",
    "    res = torch.zeros(len(samples), max_len).long() + pad_idx\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: res[i, -len(s[0]):] = torch.LongTensor(s[0])\n",
    "        else:         res[i, :len(s[0]) ] = torch.LongTensor(s[0])\n",
    "    qa_idxs = torch.cat([s[1][0].unsqueeze(0) for s in samples])\n",
    "    imp_labels = torch.tensor([s[1][1] for s in samples])\n",
    "    return res, (qa_idxs, imp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:07.479469Z",
     "start_time": "2020-01-30T19:22:07.473106Z"
    }
   },
   "outputs": [],
   "source": [
    "train_sampler = SortishSampler(ll_train.x, key=lambda t: len(ll_train[int(t)][0]), bs=config.bs)\n",
    "train_dl = DataLoader(ll_train, batch_size=config.bs, sampler=train_sampler, collate_fn=pad_collate_qa)\n",
    "\n",
    "valid_sampler = SortSampler(ll_valid.x, key=lambda t: len(ll_valid[int(t)][0]))\n",
    "valid_dl = DataLoader(ll_valid, batch_size=config.bs, sampler=valid_sampler, collate_fn=pad_collate_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:07.627019Z",
     "start_time": "2020-01-30T19:22:07.480511Z"
    }
   },
   "outputs": [],
   "source": [
    "# x,y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:07.630302Z",
     "start_time": "2020-01-30T19:22:07.628196Z"
    }
   },
   "outputs": [],
   "source": [
    "data = DataBunch(train_dl,valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:07.641578Z",
     "start_time": "2020-01-30T19:22:07.631454Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_segments(x,sep_idx=config.sep_idx):\n",
    "    res = x.new_zeros(x.size())\n",
    "    for row_idx, row in enumerate(x):\n",
    "        in_seg_1 = False\n",
    "        for val_idx,val in enumerate(row):\n",
    "            if val == sep_idx:\n",
    "                in_seg_1 = True\n",
    "            if in_seg_1: \n",
    "                res[row_idx,val_idx] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:07.648010Z",
     "start_time": "2020-01-30T19:22:07.642739Z"
    }
   },
   "outputs": [],
   "source": [
    "weights = config.output_dir/config.load_checkpoint if config.load_checkpoint else config.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:07.655831Z",
     "start_time": "2020-01-30T19:22:07.649168Z"
    }
   },
   "outputs": [],
   "source": [
    "class AlbertForQuestionAnsweringMTL(AlbertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.bert = AlbertModel(config)\n",
    "        self.qa_outputs = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.imp_outputs = nn.Linear(config.hidden_size, 2)\n",
    "        self.imp_dropout = nn.Dropout(.1)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, token_type_ids=None, position_ids=None):\n",
    "\n",
    "        outputs = self.bert(input_ids=input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "\n",
    "        sequence_output, pooled_output = outputs\n",
    "\n",
    "        logits_qa = self.qa_outputs(sequence_output)\n",
    "        start_logits, end_logits = logits_qa.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "    \n",
    "        imp_logits = self.imp_outputs(self.imp_dropout(pooled_output))\n",
    "\n",
    "        outputs = (start_logits, end_logits, imp_logits,) + outputs[2:]\n",
    "        return outputs  # start_logits, end_logits, (hidden_states), (attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:07.663168Z",
     "start_time": "2020-01-30T19:22:07.657106Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(learner,output_dir: Path):\n",
    "    def _create_dir(dirc):\n",
    "        if not os.path.exists(dirc): os.mkdir(dirc)\n",
    "    epoch = learner.epoch\n",
    "    metric = round(float(learner.qa_avg_stats.valid_stats.avg_stats[1]),2)\n",
    "    _create_dir(output_dir)\n",
    "    model_dir = f\"{config.model}-accuracy-{metric}-epoch-{epoch}-\" + str(datetime.now())\n",
    "    _create_dir(output_dir/model_dir)\n",
    "    learner.model.save_pretrained(output_dir/model_dir) # learner.model.bert.save...\n",
    "\n",
    "class SaveModelCallback(Callback):\n",
    "    def __init__(self,save_model_func,output_dir):\n",
    "        self.output_dir, self.save_model_func = output_dir,save_model_func\n",
    "    def after_epoch(self):\n",
    "        self.save_model_func(self, self.output_dir)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:07.674387Z",
     "start_time": "2020-01-30T19:22:07.665952Z"
    }
   },
   "outputs": [],
   "source": [
    "class CudaCallbackMTL(Callback):\n",
    "    def begin_fit(self): self.model.cuda()\n",
    "    def begin_batch(self): self.run.xb, self.run.yb = \\\n",
    "        self.xb.cuda(), (self.run.yb[0].cuda(), self.run.yb[1].cuda())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:07.683002Z",
     "start_time": "2020-01-30T19:22:07.676042Z"
    }
   },
   "outputs": [],
   "source": [
    "# gradient accumulation\n",
    "class GradientAccumulation(Callback):\n",
    "    def __init__(self,bs,effective_bs):\n",
    "        self.bs, self.effective_bs = bs, effective_bs\n",
    "    def after_backward(self):\n",
    "        if self.n_iter*self.bs % self.effective_bs != 0: raise CancelBatchException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:07.700584Z",
     "start_time": "2020-01-30T19:22:07.693582Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining the loss function\n",
    "def cross_entropy_qa_mtl(input, target):\n",
    "    \"\"\"\n",
    "    Summing the cross entropy loss from the starting and ending indices. \n",
    "    \"\"\"\n",
    "#     with torch.autograd.set_detect_anomaly(True):\n",
    "#         imp_loss = F.cross_entropy(input[2], target[1])\n",
    "    qa_loss = torch.add(F.cross_entropy(input[0], target[0][:,0]) , F.cross_entropy(input[1], target[0][:,1]))\n",
    "#         loss = torch.add(qa_loss, imp_loss)\n",
    "    return qa_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:07.709623Z",
     "start_time": "2020-01-30T19:22:07.701824Z"
    }
   },
   "outputs": [],
   "source": [
    "class QAAvgStats(AvgStats):\n",
    "    def accumulate(self, run):\n",
    "        bn = run.xb.shape[0]\n",
    "        self.tot_loss += run.loss * bn\n",
    "        self.count += bn\n",
    "        for i,m in enumerate(self.metrics):\n",
    "            self.tot_mets[i] += m(run.pred, run.yb, run.xb) * bn\n",
    "            \n",
    "class QAAvgStatsCallback(AvgStatsCallback):\n",
    "    def __init__(self, metrics):\n",
    "        self.train_stats,self.valid_stats = QAAvgStats(metrics,True),QAAvgStats(metrics,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:07.717988Z",
     "start_time": "2020-01-30T19:22:07.710911Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining the evaluation metrics based on squad evaluation method\n",
    "def acc_qa(input,target,xb):\n",
    "    \"\"\"\n",
    "    Taking the average between the accuracies of predicting the start and ending indices\n",
    "    \"\"\"\n",
    "    return (accuracy(input[0], target[0][:,0]) + accuracy(input[1], target[0][:,1]))\n",
    "\n",
    "def acc_imp(input,target,xb):\n",
    "    return accuracy(input[2], target[1])\n",
    "\n",
    "def exact_match(input,target,xb):\n",
    "    def _acc(out, yb): return (torch.argmax(out, dim=1)==yb).float()\n",
    "    return (_acc(input[0], target[0][:,0]) + _acc(input[1], target[0][:,1]) == 2).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:07.727062Z",
     "start_time": "2020-01-30T19:22:07.719230Z"
    }
   },
   "outputs": [],
   "source": [
    "def f1_score(input,target,xb):\n",
    "    \"\"\"\n",
    "    based on the official evaluation script:\n",
    "    https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/\n",
    "    \"\"\"\n",
    "    pred_starts,pred_ends = [torch.argmax(out, dim=1) for out in input[:2]]\n",
    "    gold_starts,gold_ends = target[0][:,0], target[0][:,1]\n",
    "    \n",
    "    def _get_toks(idx,start,end):\n",
    "        if start == end: end += 1\n",
    "        return xb[idx][start:end]\n",
    "    \n",
    "    def _score1(pred_toks,gold_toks):\n",
    "        common = collections.Counter(gold_toks.tolist()) & collections.Counter(pred_toks.tolist())\n",
    "        num_same = sum(common.values())\n",
    "        if num_same == 0: \n",
    "            return 0\n",
    "        precision = 1.0 * num_same / len(pred_toks)\n",
    "        recall = 1.0 * num_same / len(gold_toks)\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "        return f1\n",
    "    \n",
    "    pred_toks = [_get_toks(i,start,end) for i,(start,end) in enumerate(zip(pred_starts,pred_ends))]\n",
    "    gold_toks = [_get_toks(i,start,end) for i,(start,end) in enumerate(zip(gold_starts,gold_ends))]\n",
    "    score = np.mean([_score1(pred,gold) for pred,gold in zip(pred_toks,gold_toks)])\n",
    "    return score             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:36:35.347444Z",
     "start_time": "2020-01-30T19:36:35.343953Z"
    }
   },
   "outputs": [],
   "source": [
    "cbfs = [#partial(QAAvgStatsCallback,[acc_qa,acc_imp,exact_match]),#,exact_match,,f1_score]),\n",
    "        CudaCallbackMTL,\n",
    "        ProgressCallback,\n",
    "        Recorder]\n",
    "\n",
    "if not config.testing and config.save_checkpoint: \n",
    "    cbfs.append(partial(SaveModelCallback,save_model,config.output_dir))\n",
    "    \n",
    "if config.effective_bs and config.bs != config.effective_bs:\n",
    "    cbfs.append(partial(GradientAccumulation,config.bs,config.effective_bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:22:08.818749Z",
     "start_time": "2020-01-30T19:22:07.734705Z"
    }
   },
   "outputs": [],
   "source": [
    "model = AlbertForQuestionAnsweringMTL.from_pretrained(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:24:35.924987Z",
     "start_time": "2020-01-30T19:24:35.918352Z"
    }
   },
   "outputs": [],
   "source": [
    "def albert_splitter(m, g1=[],g2=[]):\n",
    "    l = list(dict(m.named_children()).keys())\n",
    "    if \"qa_outputs\" in  l: g2+= m.qa_outputs.parameters()\n",
    "    if \"imp_outputs\" in l: g2+= m.imp_outputs.parameters()\n",
    "    if isinstance(m,torch.nn.modules.normalization.LayerNorm):\n",
    "        g2+= m.parameters()\n",
    "    elif hasattr(m, 'weight'): \n",
    "        g1+= m.parameters()\n",
    "    for ll in m.children(): albert_splitter(ll, g1, g2)\n",
    "    return g1,g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:24:36.545495Z",
     "start_time": "2020-01-30T19:24:36.538435Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/fastai/course-v3/blob/master/nbs/dl2/11_train_imagenette.ipynb\n",
    "def create_phases(phases):\n",
    "    phases = listify(phases)\n",
    "    return phases + [1-sum(phases)]\n",
    "\n",
    "# https://github.com/fastai/course-v3/blob/master/nbs/dl2/11a_transfer_learning.ipynb\n",
    "def sched_1cycle(lrs, pct_start=0.3, mom_start=0.95, mom_mid=0.85, mom_end=0.95):\n",
    "    phases = create_phases(pct_start)\n",
    "    sched_lr  = [combine_scheds(phases, cos_1cycle_anneal(lr/10., lr, lr/1e5))\n",
    "                 for lr in lrs]\n",
    "    sched_mom = combine_scheds(phases, cos_1cycle_anneal(mom_start, mom_mid, mom_end))\n",
    "    return [ParamScheduler('lr', sched_lr),\n",
    "            ParamScheduler('mom', sched_mom)]\n",
    "\n",
    "disc_lr_sched = sched_1cycle([config.max_lr,config.max_lr_last], config.phases) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:24:37.152340Z",
     "start_time": "2020-01-30T19:24:37.147422Z"
    }
   },
   "outputs": [],
   "source": [
    "# the learning rate we apply here does not matter since we are scheduling \n",
    "learn = Learner(model, data, cross_entropy_qa_mtl,lr=config.max_lr,cb_funcs=cbfs,splitter=albert_splitter\\\n",
    "                ,opt_func=config.opt_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='234' class='' max='2711', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      8.63% [234/2711 02:10<23:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1,cbs=disc_lr_sched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:23:14.938767Z",
     "start_time": "2020-01-30T19:23:14.790731Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:23:14.941950Z",
     "start_time": "2020-01-30T19:23:14.939993Z"
    }
   },
   "outputs": [],
   "source": [
    "# manually save and load model weights\n",
    "\n",
    "# save_model(learn,config.out_path)\n",
    "# learn.model.bert.from_pretrained(config.output_dir/'albert-base-v2-accuracy-0.72-epoch-3-2020-01-24 16:22:37.693825')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:23:14.954319Z",
     "start_time": "2020-01-30T19:23:14.943119Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_collate_x(samples, pad_idx=config.pad_idx, pad_first=False):\n",
    "    max_len = max([len(s[0]) for s in samples])\n",
    "    res = torch.zeros(len(samples), max_len).long() + pad_idx\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: res[i, -len(s[0]):] = torch.LongTensor(s[0])\n",
    "        else:         res[i, :len(s[0]) ] = torch.LongTensor(s[0])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T19:23:15.104695Z",
     "start_time": "2020-01-30T19:23:14.955764Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tests with samples \n",
    "sample1 = \"[CLS] there have been thirty earthquakes in the past three days. [SEP] how many earthquakes have there been? [SEP]\"\n",
    "sample2 = \"[CLS] the storm took place yesterday from dawn to dusk [SEP] what took place??\"\n",
    "sample3 = \"[CLS] No.2 pencils are used a lot in schools. [SEP] what are used?\"\n",
    "# get_pred([sample1,sample2,sample3], learn.model, tok)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (qa)",
   "language": "python",
   "name": "qa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
