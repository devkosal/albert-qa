{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ALBERT for Question Answering - SQuAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updates:\n",
    "\n",
    "Things implemented:\n",
    "- Data Loading\n",
    "- Model\n",
    "- Learner\n",
    "- Prediction on new data\n",
    "- Optimizer selection\n",
    "- Segment IDs\n",
    "- F1 Score\n",
    "- Checkpoints\n",
    "- Use a more powerful machine to train\n",
    "- Gradient Accumulation\n",
    "- Squad 2.0\n",
    "    - Multi Task Learning Changes\n",
    "\n",
    "TODO:\n",
    "- Consider using the sliding window approach for long sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:42:53.355595Z",
     "start_time": "2020-02-03T17:42:52.410125Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src import *\n",
    "from transformers import AutoTokenizer, AlbertModel,AlbertPreTrainedModel, PretrainedConfig\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "import collections\n",
    "from tqdm import tqdm, trange\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "import requests\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:42:53.358777Z",
     "start_time": "2020-02-03T17:42:53.357047Z"
    }
   },
   "outputs": [],
   "source": [
    "# logging.basicConfig()\n",
    "# logger = logging.getLogger()\n",
    "# logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:08.235404Z",
     "start_time": "2020-02-03T17:43:08.073322Z"
    }
   },
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    data_path = Path(\"../data/SQuAD/2.0\"), # replace with the directory containing the parsed csv files\n",
    "    output_dir = Path(\"./models\"), # for storing model weights between epochs\n",
    "    task = \"SQuAD\",\n",
    "    squad_version = \"2.0\",\n",
    "    testing=False,\n",
    "    seed = 2020,\n",
    "    model = 'albert-base-v2',\n",
    "    max_lr=3e-5,\n",
    "    max_lr_last = 1e-4,\n",
    "    phases = .3,\n",
    "    optimizer=\"lamb\", # choose between 'adam' or 'lamb'\n",
    "    epochs=2,\n",
    "    use_fp16=False,\n",
    "    recreate_ds=False,\n",
    "    bs=4, \n",
    "    effective_bs=4, # set this different from bs to determine gradient accumulation steps (i.e. effective_bs/bs)\n",
    "    max_seq_len=512,\n",
    "    start_tok = \"[CLS]\",\n",
    "    end_tok = \"[SEP]\",\n",
    "    sep_tok = \"[SEP]\",\n",
    "    unk_tok_idx=1,\n",
    "    sep_idx=3,\n",
    "    pad_idx=0,\n",
    "    feat_cols = [\"question\",\"paragraph\"],\n",
    "    label_cols = [\"idxs\",\"is_impossible\"],\n",
    "    adjustment = 2,\n",
    "    save_checkpoint = True,\n",
    "    load_checkpoint=None,#\"2020-02-02_23_32_09.566715-albert-base-v2-accuracy-0.62-epoch-0-squad_ver-2.0\",\n",
    "    model_parameters = Config(\n",
    "        layer_norm_eps = 1e-12,\n",
    "        num_labels_clas = 2,\n",
    "        clas_dropout_prob = .1\n",
    "    )\n",
    ")\n",
    "\n",
    "config.model_name = re.findall(r\"(.+?)-\",config.model)[0]\n",
    "config.weights = config.output_dir/config.load_checkpoint if config.load_checkpoint else config.model \n",
    "r = requests.get(f\"https://s3.amazonaws.com/models.huggingface.co/bert/{config.model}-config.json\")\n",
    "config.model_config = PretrainedConfig(**r.json(),**config.model_parameters)\n",
    "\n",
    "# set optimizer\n",
    "assert config.optimizer.lower() in [\"adam\",\"lamb\"], f\"invalid optimizer in config {config.optimizer}\"\n",
    "config.opt_func = lamb_opt() if config.optimizer.lower() == \"lamb\" else adam_opt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T16:18:00.306954Z",
     "start_time": "2020-02-03T16:18:00.299161Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:08.258004Z",
     "start_time": "2020-02-03T17:43:08.240371Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def remove_max_sl(df):\n",
    "    init_len = len(df)\n",
    "    df = df[df.seq_len < config.max_seq_len-2]\n",
    "    new_len = len(df)\n",
    "    print(f\"dropping {init_len - new_len} out of {init_len} questions\")\n",
    "    return df\n",
    "\n",
    "def str2tensor(s):\n",
    "    indices = re.findall(\"-?\\d+\",s)\n",
    "    return torch.tensor([int(indices[0]), int(indices[1])], dtype=torch.long)\n",
    "\n",
    "def set_segments(x,sep_idx=config.sep_idx):\n",
    "    res = x.new_zeros(x.size())\n",
    "    for row_idx, row in enumerate(x):\n",
    "        in_seg_1 = False\n",
    "        for val_idx,val in enumerate(row):\n",
    "            if val == sep_idx:\n",
    "                in_seg_1 = True\n",
    "            if in_seg_1: \n",
    "                res[row_idx,val_idx] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:09.273451Z",
     "start_time": "2020-02-03T17:43:08.263277Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(config.data_path/f\"train_{config.squad_version}_{config.model_name}.csv\")\n",
    "valid = pd.read_csv(config.data_path/f\"val_{config.squad_version}_{config.model_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:09.560410Z",
     "start_time": "2020-02-03T17:43:09.274912Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train.drop_duplicates(inplace=True)\n",
    "valid.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:09.619218Z",
     "start_time": "2020-02-03T17:43:09.561642Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# randomizing the order of training data\n",
    "train = train.sample(frac=1).reset_index(drop=True) #random_state = config.seed\n",
    "valid = valid.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:09.631595Z",
     "start_time": "2020-02-03T17:43:09.620547Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False    0.66617\n",
       " True     0.33383\n",
       " Name: is_impossible, dtype: float64, False    0.636592\n",
       " True     0.363408\n",
       " Name: is_impossible, dtype: float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(False    0.66617\n",
       " True     0.33383\n",
       " Name: is_impossible, dtype: float64, False    0.636592\n",
       " True     0.363408\n",
       " Name: is_impossible, dtype: float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.is_impossible.value_counts(normalize=True), valid.is_impossible.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:09.635449Z",
     "start_time": "2020-02-03T17:43:09.632884Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# reduce df sizes if testing\n",
    "if config.testing:\n",
    "    train = train[:int(len(train)/20)]\n",
    "    valid = valid[:int(len(valid)/20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:09.664608Z",
     "start_time": "2020-02-03T17:43:09.636604Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping 216 out of 130294 questions\n",
      "dropping 124 out of 16315 questions\n",
      "dropping 216 out of 130294 questions\n",
      "dropping 124 out of 16315 questions\n"
     ]
    }
   ],
   "source": [
    "train, valid = remove_max_sl(train), remove_max_sl(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:09.668109Z",
     "start_time": "2020-02-03T17:43:09.666418Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train[\"idxs\"] = train.apply(lambda row: row[\"idxs\"] if not row[\"is_impossible\"] else '[-2, -2]',axis=1)\n",
    "# valid[\"idxs\"] = valid.apply(lambda row: row[\"idxs\"] if not row[\"is_impossible\"] else '[-2, -2]',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:09.683707Z",
     "start_time": "2020-02-03T17:43:09.669559Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>answer</th>\n",
       "      <th>idxs</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>ans_text</th>\n",
       "      <th>is_impossible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When was the southern tip of Africa colonized?</td>\n",
       "      <td>The Dutch East India Company had founded the C...</td>\n",
       "      <td>['▁16', '52']</td>\n",
       "      <td>[27, 29]</td>\n",
       "      <td>260</td>\n",
       "      <td>1652</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who did Elizabeth appoint as Prime Minister af...</td>\n",
       "      <td>The Suez crisis and the choice of Eden's succe...</td>\n",
       "      <td>['▁earl', '▁of', '▁home']</td>\n",
       "      <td>[101, 104]</td>\n",
       "      <td>162</td>\n",
       "      <td>Earl of Home</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Where are archival descriptions of holdings un...</td>\n",
       "      <td>Archival descriptions of the permanent holding...</td>\n",
       "      <td>['▁archival', '▁research', '▁catalog', '▁', '(...</td>\n",
       "      <td>[31, 38]</td>\n",
       "      <td>98</td>\n",
       "      <td>Archival Research Catalog (ARC)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The torque amplifiers of the differential anal...</td>\n",
       "      <td>The art of mechanical analog computing reached...</td>\n",
       "      <td>['▁h', '.', '▁w', '.', '▁', 'nie', 'man']</td>\n",
       "      <td>[66, 73]</td>\n",
       "      <td>89</td>\n",
       "      <td>H. W. Nieman</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Due to low waer tariffs, what is required to m...</td>\n",
       "      <td>Partly because of low sanitation coverage abou...</td>\n",
       "      <td>['▁government', '▁subsidies']</td>\n",
       "      <td>[61, 63]</td>\n",
       "      <td>111</td>\n",
       "      <td>government subsidies</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0     When was the southern tip of Africa colonized?   \n",
       "1  Who did Elizabeth appoint as Prime Minister af...   \n",
       "2  Where are archival descriptions of holdings un...   \n",
       "3  The torque amplifiers of the differential anal...   \n",
       "4  Due to low waer tariffs, what is required to m...   \n",
       "\n",
       "                                           paragraph  \\\n",
       "0  The Dutch East India Company had founded the C...   \n",
       "1  The Suez crisis and the choice of Eden's succe...   \n",
       "2  Archival descriptions of the permanent holding...   \n",
       "3  The art of mechanical analog computing reached...   \n",
       "4  Partly because of low sanitation coverage abou...   \n",
       "\n",
       "                                              answer        idxs  seq_len  \\\n",
       "0                                      ['▁16', '52']    [27, 29]      260   \n",
       "1                          ['▁earl', '▁of', '▁home']  [101, 104]      162   \n",
       "2  ['▁archival', '▁research', '▁catalog', '▁', '(...    [31, 38]       98   \n",
       "3          ['▁h', '.', '▁w', '.', '▁', 'nie', 'man']    [66, 73]       89   \n",
       "4                      ['▁government', '▁subsidies']    [61, 63]      111   \n",
       "\n",
       "                          ans_text  is_impossible  \n",
       "0                             1652          False  \n",
       "1                     Earl of Home          False  \n",
       "2  Archival Research Catalog (ARC)          False  \n",
       "3                     H. W. Nieman          False  \n",
       "4             government subsidies          False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>answer</th>\n",
       "      <th>idxs</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>ans_text</th>\n",
       "      <th>is_impossible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When was the southern tip of Africa colonized?</td>\n",
       "      <td>The Dutch East India Company had founded the C...</td>\n",
       "      <td>['▁16', '52']</td>\n",
       "      <td>[27, 29]</td>\n",
       "      <td>260</td>\n",
       "      <td>1652</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who did Elizabeth appoint as Prime Minister af...</td>\n",
       "      <td>The Suez crisis and the choice of Eden's succe...</td>\n",
       "      <td>['▁earl', '▁of', '▁home']</td>\n",
       "      <td>[101, 104]</td>\n",
       "      <td>162</td>\n",
       "      <td>Earl of Home</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Where are archival descriptions of holdings un...</td>\n",
       "      <td>Archival descriptions of the permanent holding...</td>\n",
       "      <td>['▁archival', '▁research', '▁catalog', '▁', '(...</td>\n",
       "      <td>[31, 38]</td>\n",
       "      <td>98</td>\n",
       "      <td>Archival Research Catalog (ARC)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The torque amplifiers of the differential anal...</td>\n",
       "      <td>The art of mechanical analog computing reached...</td>\n",
       "      <td>['▁h', '.', '▁w', '.', '▁', 'nie', 'man']</td>\n",
       "      <td>[66, 73]</td>\n",
       "      <td>89</td>\n",
       "      <td>H. W. Nieman</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Due to low waer tariffs, what is required to m...</td>\n",
       "      <td>Partly because of low sanitation coverage abou...</td>\n",
       "      <td>['▁government', '▁subsidies']</td>\n",
       "      <td>[61, 63]</td>\n",
       "      <td>111</td>\n",
       "      <td>government subsidies</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0     When was the southern tip of Africa colonized?   \n",
       "1  Who did Elizabeth appoint as Prime Minister af...   \n",
       "2  Where are archival descriptions of holdings un...   \n",
       "3  The torque amplifiers of the differential anal...   \n",
       "4  Due to low waer tariffs, what is required to m...   \n",
       "\n",
       "                                           paragraph  \\\n",
       "0  The Dutch East India Company had founded the C...   \n",
       "1  The Suez crisis and the choice of Eden's succe...   \n",
       "2  Archival descriptions of the permanent holding...   \n",
       "3  The art of mechanical analog computing reached...   \n",
       "4  Partly because of low sanitation coverage abou...   \n",
       "\n",
       "                                              answer        idxs  seq_len  \\\n",
       "0                                      ['▁16', '52']    [27, 29]      260   \n",
       "1                          ['▁earl', '▁of', '▁home']  [101, 104]      162   \n",
       "2  ['▁archival', '▁research', '▁catalog', '▁', '(...    [31, 38]       98   \n",
       "3          ['▁h', '.', '▁w', '.', '▁', 'nie', 'man']    [66, 73]       89   \n",
       "4                      ['▁government', '▁subsidies']    [61, 63]      111   \n",
       "\n",
       "                          ans_text  is_impossible  \n",
       "0                             1652          False  \n",
       "1                     Earl of Home          False  \n",
       "2  Archival Research Catalog (ARC)          False  \n",
       "3                     H. W. Nieman          False  \n",
       "4             government subsidies          False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setting up the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:09.691833Z",
     "start_time": "2020-02-03T17:43:09.684965Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TokenizerProcessor(Processor):\n",
    "    def __init__(self, tok_func, max_sl, start_tok, end_tok, pre_rules=None,post_rules=None):\n",
    "        self.tok_func,self.max_sl = tok_func,max_sl\n",
    "        self.pre_rules,self.post_rules=pre_rules,post_rules\n",
    "        self.start_tok, self.end_tok = start_tok, end_tok\n",
    "\n",
    "    def proc1(self, x): return [self.start_tok] + self.tok_func(x)[:self.max_sl-2] + [self.end_tok]\n",
    "    \n",
    "    def __call__(self, items): return tqdm([self.proc1(x) for x in items])\n",
    "\n",
    "class NumericalizeProcessor(Processor):\n",
    "    \"\"\"\n",
    "    only works with an existing vocab at the moment and min_freq is not accounted for\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab:dict, unk_tok_idx:int, min_freq=2): \n",
    "        self.vocab, self.unk_tok_idx, self.min_freq = vocab, unk_tok_idx, min_freq\n",
    "    \n",
    "    def proc1(self, x): return [self.vocab[i] if i in self.vocab else self.unk_tok_idx for i in x]\n",
    "    \n",
    "    def __call__(self, items): \n",
    "        if getattr(self, 'otoi', None) is None:\n",
    "            self.otoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.vocab)})\n",
    "        return tqdm([self.proc1(x) for x in items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:09.899469Z",
     "start_time": "2020-02-03T17:43:09.692930Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tok = AutoTokenizer.from_pretrained(config.model)\n",
    "proc_tok = TokenizerProcessor(tok.tokenize, config.max_seq_len, config.start_tok, config.end_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:09.933161Z",
     "start_time": "2020-02-03T17:43:09.900598Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vocab = {tok.convert_ids_to_tokens(i):i for i in range(tok.vocab_size)}\n",
    "proc_num = NumericalizeProcessor(vocab, unk_tok_idx=config.unk_tok_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:09.944982Z",
     "start_time": "2020-02-03T17:43:09.934278Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class QALabelProcessor(Processor):\n",
    "    def __init__(self, parse_func = noop, adjustment = 2):\n",
    "        self.parse_func = parse_func\n",
    "        self.adjustment = adjustment\n",
    "        self.vocab=[False, True]\n",
    "        self.otoi=None\n",
    "        \n",
    "    def cat_proc1(self,item): return self.otoi[item]\n",
    "    def index_proc1(self, item): return self.parse_func(item) + self.adjustment\n",
    "    \n",
    "    def __call__(self, items): \n",
    "        if self.otoi is None:\n",
    "            self.otoi  = {v:k for k,v in enumerate(self.vocab)}\n",
    "        return [(self.index_proc1(item[0]),self.cat_proc1(item[1])) for item in items] # we want the \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:09.950772Z",
     "start_time": "2020-02-03T17:43:09.946100Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "proc_qa = QALabelProcessor(str2tensor,config.adjustment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:09.957911Z",
     "start_time": "2020-02-03T17:43:09.951788Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SquadTextList(ItemList):      \n",
    "    @classmethod  \n",
    "    def from_df(cls, df, feat_cols, label_cols, sep_tok, test=False):\n",
    "        feat_cols = listify(feat_cols)\n",
    "        x = df[feat_cols[0]]\n",
    "        for i in range(1,len(feat_cols)):\n",
    "            x += f\" {sep_tok} \" + df[feat_cols[i]]\n",
    "        labels = cls(df[label_cols].values) if not test else cls([[None,None] for _ in len(df)])\n",
    "        return cls(x,labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:16.682884Z",
     "start_time": "2020-02-03T17:43:09.959058Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if (not (config.data_path/f\"squad_{config.squad_version}_data_trn.pkl\").exists()) or config.recreate_ds or config.testing:\n",
    "    il_train = SquadTextList.from_df(train,config.feat_cols,config.label_cols,config.sep_tok)\n",
    "    il_valid = SquadTextList.from_df(valid,config.feat_cols,config.label_cols,config.sep_tok)\n",
    "\n",
    "    ll_valid = LabeledData(il_valid,il_valid.labels,proc_x = [proc_tok,proc_num], proc_y=[proc_qa])\n",
    "    ll_train = LabeledData(il_train,il_train.labels,proc_x = [proc_tok,proc_num], proc_y=[proc_qa])\n",
    "\n",
    "    # saving/loading presaved data if not testing\n",
    "    if not config.testing:\n",
    "        # save an object\n",
    "        pickle.dump(ll_train, open( config.data_path/f\"squad_{config.squad_version}_data_trn.pkl\", \"wb\" ) )\n",
    "        pickle.dump(ll_valid, open( config.data_path/f\"squad_{config.squad_version}_data_val.pkl\", \"wb\" ) )\n",
    "else:\n",
    "    # load an object\n",
    "    ll_train = pickle.load( open( config.data_path/f\"squad_{config.squad_version}_data_trn.pkl\", \"rb\" ) )\n",
    "    ll_valid = pickle.load( open( config.data_path/f\"squad_{config.squad_version}_data_val.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:16.687563Z",
     "start_time": "2020-02-03T17:43:16.684123Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Sampler\n",
    "\n",
    "class SortSampler(Sampler):\n",
    "    def __init__(self, data_source, key): self.data_source,self.key = data_source,key\n",
    "    def __len__(self): return len(self.data_source)\n",
    "    def __iter__(self):\n",
    "        return iter(sorted(list(range(len(self.data_source))), key=self.key, reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:16.703517Z",
     "start_time": "2020-02-03T17:43:16.688703Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SortishSampler(Sampler):\n",
    "    def __init__(self, data_source, key, bs):\n",
    "        self.data_source,self.key,self.bs = data_source,key,bs\n",
    "\n",
    "    def __len__(self) -> int: return len(self.data_source)\n",
    "\n",
    "    def __iter__(self):\n",
    "        idxs = torch.randperm(len(self.data_source))\n",
    "        megabatches = [idxs[i:i+self.bs*50] for i in range(0, len(idxs), self.bs*50)]\n",
    "        sorted_idx = torch.cat([tensor(sorted(s, key=self.key, reverse=True)) for s in megabatches])\n",
    "        batches = [sorted_idx[i:i+self.bs] for i in range(0, len(sorted_idx), self.bs)]\n",
    "        max_idx = torch.argmax(tensor([self.key(ck[0]) for ck in batches]))  # find the chunk with the largest key,\n",
    "        batches[0],batches[max_idx] = batches[max_idx],batches[0]            # then make sure it goes first.\n",
    "        batch_idxs = torch.randperm(len(batches)-2)\n",
    "        sorted_idx = torch.cat([batches[i+1] for i in batch_idxs]) if len(batches) > 1 else LongTensor([])\n",
    "        sorted_idx = torch.cat([batches[0], sorted_idx, batches[-1]])\n",
    "        return iter(sorted_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:16.715186Z",
     "start_time": "2020-02-03T17:43:16.704727Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def pad_collate_qa(samples, pad_idx=config.pad_idx, pad_first=False):\n",
    "    max_len = max([len(s[0]) for s in samples])\n",
    "    res = torch.zeros(len(samples), max_len).long() + pad_idx\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: res[i, -len(s[0]):] = torch.LongTensor(s[0])\n",
    "        else:         res[i, :len(s[0]) ] = torch.LongTensor(s[0])\n",
    "    qa_idxs = torch.cat([s[1][0].unsqueeze(0) for s in samples])\n",
    "    imp_labels = torch.tensor([s[1][1] for s in samples])\n",
    "    return res, (qa_idxs, imp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:16.721700Z",
     "start_time": "2020-02-03T17:43:16.716315Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_sampler = SortishSampler(ll_train.x, key=lambda t: len(ll_train[int(t)][0]), bs=config.bs)\n",
    "train_dl = DataLoader(ll_train, batch_size=config.bs, sampler=train_sampler, collate_fn=pad_collate_qa)\n",
    "\n",
    "valid_sampler = SortSampler(ll_valid.x, key=lambda t: len(ll_valid[int(t)][0]))\n",
    "valid_dl = DataLoader(ll_valid, batch_size=config.bs, sampler=valid_sampler, collate_fn=pad_collate_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:16.726739Z",
     "start_time": "2020-02-03T17:43:16.722836Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# x,y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setting up the Databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:16.732059Z",
     "start_time": "2020-02-03T17:43:16.727805Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = DataBunch(train_dl,valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Base QA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:16.741581Z",
     "start_time": "2020-02-03T17:43:16.733051Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class AlbertForQuestionAnswering(AlbertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.albert = AlbertModel(config)\n",
    "        self.qa_outputs = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        start_positions=None,\n",
    "        end_positions=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        start_positions (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`, defaults to :obj:`None`):\n",
    "            Labels for position (index) of the start of the labelled span for computing the token classification loss.\n",
    "            Positions are clamped to the length of the sequence (`sequence_length`).\n",
    "            Position outside of the sequence are not taken into account for computing the loss.\n",
    "        end_positions (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`, defaults to :obj:`None`):\n",
    "            Labels for position (index) of the end of the labelled span for computing the token classification loss.\n",
    "            Positions are clamped to the length of the sequence (`sequence_length`).\n",
    "            Position outside of the sequence are not taken into account for computing the loss.\n",
    "    Returns:\n",
    "        :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.AlbertConfig`) and inputs:\n",
    "        loss: (`optional`, returned when ``labels`` is provided) ``torch.FloatTensor`` of shape ``(1,)``:\n",
    "            Total span extraction loss is the sum of a Cross-Entropy for the start and end positions.\n",
    "        start_scores ``torch.FloatTensor`` of shape ``(batch_size, sequence_length,)``\n",
    "            Span-start scores (before SoftMax).\n",
    "        end_scores: ``torch.FloatTensor`` of shape ``(batch_size, sequence_length,)``\n",
    "            Span-end scores (before SoftMax).\n",
    "        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n",
    "            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n",
    "            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n",
    "            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
    "        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n",
    "            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape\n",
    "            :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n",
    "            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
    "            heads.\n",
    "    Examples::\n",
    "        # The checkpoint albert-base-v2 is not fine-tuned for question answering. Please see the\n",
    "        # examples/run_squad.py example to see how to fine-tune a model to a question answering task.\n",
    "        from transformers import AlbertTokenizer, AlbertForQuestionAnswering\n",
    "        import torch\n",
    "        tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "        model = AlbertForQuestionAnswering.from_pretrained('albert-base-v2')\n",
    "        question, text = \"Who was Jim Henson?\", \"Jim Henson was a nice puppet\"\n",
    "        input_dict = tokenizer.encode_plus(question, text, return_tensors='pt')\n",
    "        start_scores, end_scores = model(**input_dict)\n",
    "        \"\"\"\n",
    "\n",
    "        outputs = self.albert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "\n",
    "        sequence_output, pooled_output = outputs[:2]\n",
    "\n",
    "        logits = self.qa_outputs(sequence_output)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "\n",
    "        outputs = (start_logits, end_logits,) + outputs[2:]\n",
    "        if start_positions is not None and end_positions is not None:\n",
    "            # If we are on multi-GPU, split add a dimension\n",
    "            if len(start_positions.size()) > 1:\n",
    "                start_positions = start_positions.squeeze(-1)\n",
    "            if len(end_positions.size()) > 1:\n",
    "                end_positions = end_positions.squeeze(-1)\n",
    "            # sometimes the start/end positions are outside our model inputs, we ignore these terms\n",
    "            ignored_index = start_logits.size(1)\n",
    "            start_positions.clamp_(0, ignored_index)\n",
    "            end_positions.clamp_(0, ignored_index)\n",
    "\n",
    "            loss_fct = CrossEntropyLoss(ignore_index=ignored_index)\n",
    "            start_loss = loss_fct(start_logits, start_positions)\n",
    "            end_loss = loss_fct(end_logits, end_positions)\n",
    "            total_loss = (start_loss + end_loss) / 2\n",
    "            outputs = (total_loss,) + outputs\n",
    "\n",
    "        return outputs + (pooled_output,)  # (loss), start_logits, end_logits, (hidden_states), (attentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom MTL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:16.748712Z",
     "start_time": "2020-02-03T17:43:16.742701Z"
    }
   },
   "outputs": [],
   "source": [
    "class AlbertForQuestionAnsweringMTL(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(AlbertForQuestionAnsweringMTL,self).__init__()\n",
    "        m_config = config.model_config # this config contains the model specific parameters\n",
    "        self.bert = AlbertForQuestionAnswering(m_config) if config.load_checkpoint else\\\n",
    "        AlbertForQuestionAnswering.from_pretrained(config.model)\n",
    "        self.bert.train()\n",
    "        self.poss_drop = nn.Dropout(m_config.clas_dropout_prob)\n",
    "        self.poss = nn.Linear(m_config.hidden_size,m_config.num_labels_clas)\n",
    "        \n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):       \n",
    "        token_type_ids = set_segments(input_ids)\n",
    "        outputs = self.bert(input_ids,token_type_ids=token_type_ids)\n",
    "        poss_outputs = self.poss_drop(self.poss(outputs[2]))\n",
    "        return outputs[:2] + (poss_outputs,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:17.559477Z",
     "start_time": "2020-02-03T17:43:16.749846Z"
    }
   },
   "outputs": [],
   "source": [
    "model = AlbertForQuestionAnsweringMTL(config)\n",
    "if config.load_checkpoint:\n",
    "    st = torch.load(config.output_dir/config.load_checkpoint/\"weights.bin\")\n",
    "    learn.model.load_state_dict(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function and Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:17.566222Z",
     "start_time": "2020-02-03T17:43:17.562012Z"
    }
   },
   "outputs": [],
   "source": [
    "def assert_no_negs(tensor):\n",
    "    assert torch.all(torch.eq(tensor, abs(tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:17.578825Z",
     "start_time": "2020-02-03T17:43:17.567560Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining the loss function\n",
    "# defining the loss function\n",
    "def cross_entropy_qa_mtl(input, target):\n",
    "    \"\"\"\n",
    "    Summing the cross entropy loss from the starting and ending indices. \n",
    "    \"\"\"\n",
    "    loss = torch.add(F.cross_entropy(input[0], target[0][:,0]) , F.cross_entropy(input[1], target[0][:,1]))\n",
    "    poss_loss = F.cross_entropy(input[2], target[1])\n",
    "    return torch.add(loss, poss_loss)\n",
    "\n",
    "# def cross_entropy_qa_mtl(input, target):\n",
    "#     \"\"\"\n",
    "#     Summing the cross entropy loss from the starting and ending indices. \n",
    "#     \"\"\"\n",
    "#     assert_no_negs(target[0])\n",
    "#     assert_no_negs(target[1])\n",
    "    \n",
    "#     mask = (~target[1].bool()).float()\n",
    "#     qa_loss = torch.add(F.cross_entropy(input[0], target[0][:,0], reduction=\"none\"),\\\n",
    "#                         F.cross_entropy(input[1], target[0][:,1], reduction=\"none\"))/2.0\n",
    "#     qa_loss.mul_(mask+1)\n",
    "#     wtd_qa_loss = qa_loss.mean()\n",
    "\n",
    "#     imp_loss = F.cross_entropy(input[2], target[1])\n",
    "    \n",
    "#     loss = torch.add(wtd_qa_loss, imp_loss)\n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:17.587708Z",
     "start_time": "2020-02-03T17:43:17.579840Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining the evaluation metrics based on squad evaluation method\n",
    "def acc_qa(input,target,xb):\n",
    "    \"\"\"\n",
    "    Taking the average between the accuracies of predicting the start and ending indices\n",
    "    \"\"\"\n",
    "    return (accuracy(input[0], target[0][:,0]) + accuracy(input[1], target[0][:,1]))/2.0\n",
    "\n",
    "def acc_imp(input,target,xb):\n",
    "    return accuracy(input[2], target[1])\n",
    "\n",
    "def exact_match(input,target,xb):\n",
    "    def _acc(out, yb): return (torch.argmax(out, dim=1)==yb).float()\n",
    "    return (_acc(input[0], target[0][:,0]) + _acc(input[1], target[0][:,1]) == 2).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:17.597308Z",
     "start_time": "2020-02-03T17:43:17.588700Z"
    }
   },
   "outputs": [],
   "source": [
    "def f1_score(input,target,xb):\n",
    "    \"\"\"\n",
    "    based on the official evaluation script:\n",
    "    https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/\n",
    "    \"\"\"\n",
    "    pred_starts,pred_ends = [torch.argmax(out, dim=1) for out in input[:2]]\n",
    "    gold_starts,gold_ends = target[0][:,0], target[0][:,1]\n",
    "    \n",
    "    def _get_toks(idx,start,end):\n",
    "        if start == end: end += 1\n",
    "        return xb[idx][start:end]\n",
    "    \n",
    "    def _score1(pred_toks,gold_toks):\n",
    "        common = collections.Counter(gold_toks.tolist()) & collections.Counter(pred_toks.tolist())\n",
    "        num_same = sum(common.values())\n",
    "        if num_same == 0: \n",
    "            return 0\n",
    "        precision = 1.0 * num_same / len(pred_toks)\n",
    "        recall = 1.0 * num_same / len(gold_toks)\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "        return f1\n",
    "    \n",
    "    pred_toks = [_get_toks(i,start,end) for i,(start,end) in enumerate(zip(pred_starts,pred_ends))]\n",
    "    gold_toks = [_get_toks(i,start,end) for i,(start,end) in enumerate(zip(gold_starts,gold_ends))]\n",
    "    score = np.mean([_score1(pred,gold) for pred,gold in zip(pred_toks,gold_toks)])\n",
    "    return score             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:17.609182Z",
     "start_time": "2020-02-03T17:43:17.598456Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(learner,output_dir: Path):\n",
    "    def _create_dir(dirc):\n",
    "        if not os.path.exists(dirc): os.mkdir(dirc)\n",
    "    epoch = learner.epoch\n",
    "    metric = round(float(learner.qa_avg_stats.valid_stats.avg_stats[1]),2)\n",
    "    _create_dir(output_dir)\n",
    "    model_dir = f\"{re.sub(r'[ :]+','_',str(datetime.now()))}-{config.model}-accuracy-{metric}-epoch-{epoch}-squad_ver-{config.squad_version}\"\n",
    "    _create_dir(output_dir/model_dir)\n",
    "    st = learner.model.state_dict()\n",
    "    logging.info(f\"saving model in {output_dir/model_dir}\")\n",
    "    torch.save(st,output_dir/model_dir/\"weights.bin\") \n",
    "\n",
    "class SaveModelCallback(Callback):\n",
    "    def __init__(self,save_model_func,output_dir):\n",
    "        self.output_dir, self.save_model_func = output_dir,save_model_func\n",
    "    def after_epoch(self):\n",
    "        self.save_model_func(self, self.output_dir)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:17.618362Z",
     "start_time": "2020-02-03T17:43:17.610389Z"
    }
   },
   "outputs": [],
   "source": [
    "class CudaCallbackMTL(Callback):\n",
    "    def begin_fit(self): self.model.cuda()\n",
    "    def begin_batch(self): self.run.xb, self.run.yb = \\\n",
    "        self.xb.cuda(), (self.run.yb[0].cuda(), self.run.yb[1].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:17.625025Z",
     "start_time": "2020-02-03T17:43:17.619541Z"
    }
   },
   "outputs": [],
   "source": [
    "# gradient accumulation\n",
    "class GradientAccumulation(Callback):\n",
    "    _order=2\n",
    "    def __init__(self,bs,effective_bs):\n",
    "        self.bs, self.effective_bs = bs, effective_bs\n",
    "    def after_loss(self):\n",
    "        self.loss.div_(self.effective_bs/self.bs)\n",
    "    def after_backward(self):\n",
    "        if self.n_iter*self.bs % self.effective_bs != 0: raise CancelBatchException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:17.630917Z",
     "start_time": "2020-02-03T17:43:17.626152Z"
    }
   },
   "outputs": [],
   "source": [
    "class QAAvgStats(AvgStats):\n",
    "    def accumulate(self, run):\n",
    "        bn = run.xb.shape[0]\n",
    "        self.tot_loss += run.loss * bn\n",
    "        self.count += bn\n",
    "        for i,m in enumerate(self.metrics):\n",
    "            self.tot_mets[i] += m(run.pred, run.yb, run.xb) * bn\n",
    "            \n",
    "class QAAvgStatsCallback(AvgStatsCallback):\n",
    "    def __init__(self, metrics):\n",
    "        self.train_stats,self.valid_stats = QAAvgStats(metrics,True),QAAvgStats(metrics,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:17.636260Z",
     "start_time": "2020-02-03T17:43:17.631938Z"
    }
   },
   "outputs": [],
   "source": [
    "class TrainStatsCallback(Callback):\n",
    "    _order=5\n",
    "    def __init__(self, update_freq_pct=.05):\n",
    "        self.update_freq_pct = update_freq_pct\n",
    "        logging.basicConfig()\n",
    "        self.logger = logging.getLogger()\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.iter = 0\n",
    "        self.update_freq = int(self.update_freq_pct*len(self.dl))\n",
    "        \n",
    "    def after_batch(self):\n",
    "        if not self.in_train: return \n",
    "        self.iter += 1\n",
    "        if self.n_iter % self.update_freq == 0:\n",
    "            stats = learn.qa_avg_stats.train_stats \n",
    "            self.logger.info(f\"epoch {self.epoch} stats for {self.iter} out of {self.iters} are : {stats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:17.641771Z",
     "start_time": "2020-02-03T17:43:17.637262Z"
    }
   },
   "outputs": [],
   "source": [
    "cbfs = [partial(QAAvgStatsCallback,[acc_qa,acc_imp,exact_match]),#,exact_match,,f1_score]),\n",
    "        CudaCallbackMTL,\n",
    "        ProgressCallback,\n",
    "        Recorder,\n",
    "        TrainStatsCallback]\n",
    "\n",
    "if not config.testing and config.save_checkpoint: \n",
    "    cbfs.append(partial(SaveModelCallback,save_model,config.output_dir))\n",
    "    \n",
    "if config.effective_bs and config.bs != config.effective_bs:\n",
    "    cbfs.append(partial(GradientAccumulation,config.bs,config.effective_bs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:17.648497Z",
     "start_time": "2020-02-03T17:43:17.642789Z"
    }
   },
   "outputs": [],
   "source": [
    "def albert_splitter(m, g1=[],g2=[]):\n",
    "    l = list(dict(m.named_children()).keys())\n",
    "    if \"qa_outputs\" in  l: g2+= m.qa_outputs.parameters()\n",
    "    if \"imp_outputs\" in l: g2+= m.imp_outputs.parameters()\n",
    "    if isinstance(m,torch.nn.modules.normalization.LayerNorm):\n",
    "        g1+= m.parameters()\n",
    "    elif hasattr(m, 'weight'): \n",
    "        g1+= m.parameters()\n",
    "    for ll in m.children(): albert_splitter(ll, g1, g2)\n",
    "    return g1,g2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:17.656391Z",
     "start_time": "2020-02-03T17:43:17.649529Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/fastai/course-v3/blob/master/nbs/dl2/11_train_imagenette.ipynb\n",
    "def create_phases(phases):\n",
    "    phases = listify(phases)\n",
    "    return phases + [1-sum(phases)]\n",
    "\n",
    "# https://github.com/fastai/course-v3/blob/master/nbs/dl2/11a_transfer_learning.ipynb\n",
    "def sched_1cycle(lrs, pct_start=0.3, mom_start=0.95, mom_mid=0.85, mom_end=0.95):\n",
    "    phases = create_phases(pct_start)\n",
    "    sched_lr  = [combine_scheds(phases, cos_1cycle_anneal(lr/10., lr, lr/1e5))\n",
    "                 for lr in lrs]\n",
    "    sched_mom = combine_scheds(phases, cos_1cycle_anneal(mom_start, mom_mid, mom_end))\n",
    "    return [ParamScheduler('lr', sched_lr),\n",
    "            ParamScheduler('mom', sched_mom)]\n",
    "\n",
    "disc_lr_sched = sched_1cycle([config.max_lr,config.max_lr_last], config.phases) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T17:43:17.664596Z",
     "start_time": "2020-02-03T17:43:17.657400Z"
    }
   },
   "outputs": [],
   "source": [
    "# the learning rate we apply here does not matter since we are scheduling \n",
    "learn = Learner(model, data, cross_entropy_qa_mtl,lr=config.max_lr,cb_funcs=cbfs,splitter=albert_splitter\\\n",
    "                ,opt_func=config.opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T23:19:19.137553Z",
     "start_time": "2020-02-03T17:43:17.665630Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='2', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [1/2 08:23<08:23]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc_qa</th>\n",
       "      <th>train_acc_imp</th>\n",
       "      <th>train_exact_match</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_acc_qa</th>\n",
       "      <th>valid_acc_imp</th>\n",
       "      <th>valid_exact_match</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.080513</td>\n",
       "      <td>0.644321</td>\n",
       "      <td>0.786159</td>\n",
       "      <td>0.512200</td>\n",
       "      <td>3.203301</td>\n",
       "      <td>0.609968</td>\n",
       "      <td>0.809400</td>\n",
       "      <td>0.458650</td>\n",
       "      <td>2:47:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.983269</td>\n",
       "      <td>0.743392</td>\n",
       "      <td>0.883408</td>\n",
       "      <td>0.624564</td>\n",
       "      <td>3.032758</td>\n",
       "      <td>0.620499</td>\n",
       "      <td>0.850473</td>\n",
       "      <td>0.467791</td>\n",
       "      <td>2:48:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='4048', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='2', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [1/2 08:23<08:23]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc_qa</th>\n",
       "      <th>train_acc_imp</th>\n",
       "      <th>train_exact_match</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_acc_qa</th>\n",
       "      <th>valid_acc_imp</th>\n",
       "      <th>valid_exact_match</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.080513</td>\n",
       "      <td>0.644321</td>\n",
       "      <td>0.786159</td>\n",
       "      <td>0.512200</td>\n",
       "      <td>3.203301</td>\n",
       "      <td>0.609968</td>\n",
       "      <td>0.809400</td>\n",
       "      <td>0.458650</td>\n",
       "      <td>2:47:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.983269</td>\n",
       "      <td>0.743392</td>\n",
       "      <td>0.883408</td>\n",
       "      <td>0.624564</td>\n",
       "      <td>3.032758</td>\n",
       "      <td>0.620499</td>\n",
       "      <td>0.850473</td>\n",
       "      <td>0.467791</td>\n",
       "      <td>2:48:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='4048', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:epoch 0 stats for 1626 out of 32520 are : train: [8.309704244503383, tensor(0.1681, device='cuda:0'), tensor(0.6328, device='cuda:0'), tensor(0.0624, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 1626 out of 32520 are : train: [8.309704244503383, tensor(0.1681, device='cuda:0'), tensor(0.6328, device='cuda:0'), tensor(0.0624, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 3252 out of 32520 are : train: [6.414985009225092, tensor(0.3399, device='cuda:0'), tensor(0.6395, device='cuda:0'), tensor(0.2086, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 3252 out of 32520 are : train: [6.414985009225092, tensor(0.3399, device='cuda:0'), tensor(0.6395, device='cuda:0'), tensor(0.2086, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 4878 out of 32520 are : train: [5.526458077080771, tensor(0.4224, device='cuda:0'), tensor(0.6505, device='cuda:0'), tensor(0.2841, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 4878 out of 32520 are : train: [5.526458077080771, tensor(0.4224, device='cuda:0'), tensor(0.6505, device='cuda:0'), tensor(0.2841, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 6504 out of 32520 are : train: [4.98699207939345, tensor(0.4751, device='cuda:0'), tensor(0.6616, device='cuda:0'), tensor(0.3347, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 6504 out of 32520 are : train: [4.98699207939345, tensor(0.4751, device='cuda:0'), tensor(0.6616, device='cuda:0'), tensor(0.3347, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 8130 out of 32520 are : train: [4.622940690344404, tensor(0.5079, device='cuda:0'), tensor(0.6763, device='cuda:0'), tensor(0.3660, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 8130 out of 32520 are : train: [4.622940690344404, tensor(0.5079, device='cuda:0'), tensor(0.6763, device='cuda:0'), tensor(0.3660, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 9756 out of 32520 are : train: [4.345316343788438, tensor(0.5334, device='cuda:0'), tensor(0.6900, device='cuda:0'), tensor(0.3921, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 9756 out of 32520 are : train: [4.345316343788438, tensor(0.5334, device='cuda:0'), tensor(0.6900, device='cuda:0'), tensor(0.3921, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 11382 out of 32520 are : train: [4.131139079247935, tensor(0.5519, device='cuda:0'), tensor(0.7020, device='cuda:0'), tensor(0.4107, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 11382 out of 32520 are : train: [4.131139079247935, tensor(0.5519, device='cuda:0'), tensor(0.7020, device='cuda:0'), tensor(0.4107, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 13008 out of 32520 are : train: [3.9548252757918205, tensor(0.5680, device='cuda:0'), tensor(0.7136, device='cuda:0'), tensor(0.4281, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 13008 out of 32520 are : train: [3.9548252757918205, tensor(0.5680, device='cuda:0'), tensor(0.7136, device='cuda:0'), tensor(0.4281, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 14634 out of 32520 are : train: [3.813480432981413, tensor(0.5805, device='cuda:0'), tensor(0.7230, device='cuda:0'), tensor(0.4416, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 14634 out of 32520 are : train: [3.813480432981413, tensor(0.5805, device='cuda:0'), tensor(0.7230, device='cuda:0'), tensor(0.4416, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 16260 out of 32520 are : train: [3.6913781422970477, tensor(0.5906, device='cuda:0'), tensor(0.7327, device='cuda:0'), tensor(0.4524, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 16260 out of 32520 are : train: [3.6913781422970477, tensor(0.5906, device='cuda:0'), tensor(0.7327, device='cuda:0'), tensor(0.4524, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 17886 out of 32520 are : train: [3.597475854019904, tensor(0.5986, device='cuda:0'), tensor(0.7406, device='cuda:0'), tensor(0.4607, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 17886 out of 32520 are : train: [3.597475854019904, tensor(0.5986, device='cuda:0'), tensor(0.7406, device='cuda:0'), tensor(0.4607, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 19512 out of 32520 are : train: [3.5141055023831487, tensor(0.6061, device='cuda:0'), tensor(0.7478, device='cuda:0'), tensor(0.4697, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 19512 out of 32520 are : train: [3.5141055023831487, tensor(0.6061, device='cuda:0'), tensor(0.7478, device='cuda:0'), tensor(0.4697, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 21138 out of 32520 are : train: [3.4369212141640646, tensor(0.6129, device='cuda:0'), tensor(0.7544, device='cuda:0'), tensor(0.4775, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 21138 out of 32520 are : train: [3.4369212141640646, tensor(0.6129, device='cuda:0'), tensor(0.7544, device='cuda:0'), tensor(0.4775, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 22764 out of 32520 are : train: [3.370144471534001, tensor(0.6189, device='cuda:0'), tensor(0.7607, device='cuda:0'), tensor(0.4838, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 22764 out of 32520 are : train: [3.370144471534001, tensor(0.6189, device='cuda:0'), tensor(0.7607, device='cuda:0'), tensor(0.4838, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 24390 out of 32520 are : train: [3.3102353679786796, tensor(0.6240, device='cuda:0'), tensor(0.7661, device='cuda:0'), tensor(0.4894, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 24390 out of 32520 are : train: [3.3102353679786796, tensor(0.6240, device='cuda:0'), tensor(0.7661, device='cuda:0'), tensor(0.4894, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 26016 out of 32520 are : train: [3.2560005141067037, tensor(0.6289, device='cuda:0'), tensor(0.7705, device='cuda:0'), tensor(0.4948, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 26016 out of 32520 are : train: [3.2560005141067037, tensor(0.6289, device='cuda:0'), tensor(0.7705, device='cuda:0'), tensor(0.4948, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 27642 out of 32520 are : train: [3.2083240064937413, tensor(0.6329, device='cuda:0'), tensor(0.7748, device='cuda:0'), tensor(0.4993, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 27642 out of 32520 are : train: [3.2083240064937413, tensor(0.6329, device='cuda:0'), tensor(0.7748, device='cuda:0'), tensor(0.4993, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 29268 out of 32520 are : train: [3.1631634805931395, tensor(0.6370, device='cuda:0'), tensor(0.7790, device='cuda:0'), tensor(0.5041, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 29268 out of 32520 are : train: [3.1631634805931395, tensor(0.6370, device='cuda:0'), tensor(0.7790, device='cuda:0'), tensor(0.5041, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 30894 out of 32520 are : train: [3.121256099485337, tensor(0.6407, device='cuda:0'), tensor(0.7827, device='cuda:0'), tensor(0.5084, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 30894 out of 32520 are : train: [3.121256099485337, tensor(0.6407, device='cuda:0'), tensor(0.7827, device='cuda:0'), tensor(0.5084, device='cuda:0')]\n",
      "INFO:root:epoch 0 stats for 32520 out of 32520 are : train: [3.080512509801811, tensor(0.6443, device='cuda:0'), tensor(0.7862, device='cuda:0'), tensor(0.5122, device='cuda:0')]\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "INFO:root:epoch 1 stats for 6504 out of 32520 are : train: [2.0665505422144066, tensor(0.7349, device='cuda:0'), tensor(0.8756, device='cuda:0'), tensor(0.6116, device='cuda:0')]\n",
      "INFO:root:epoch 1 stats for 8130 out of 32520 are : train: [2.067942804428044, tensor(0.7351, device='cuda:0'), tensor(0.8752, device='cuda:0'), tensor(0.6120, device='cuda:0')]\n",
      "INFO:root:epoch 1 stats for 9756 out of 32520 are : train: [2.06927327574057, tensor(0.7354, device='cuda:0'), tensor(0.8751, device='cuda:0'), tensor(0.6127, device='cuda:0')]\n",
      "INFO:root:epoch 1 stats for 11382 out of 32520 are : train: [2.058265998396591, tensor(0.7366, device='cuda:0'), tensor(0.8756, device='cuda:0'), tensor(0.6149, device='cuda:0')]\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:epoch 1 stats for 17886 out of 32520 are : train: [2.0338078664877557, tensor(0.7388, device='cuda:0'), tensor(0.8790, device='cuda:0'), tensor(0.6179, device='cuda:0')]\n",
      "INFO:root:epoch 1 stats for 19512 out of 32520 are : train: [2.0279303281314065, tensor(0.7394, device='cuda:0'), tensor(0.8791, device='cuda:0'), tensor(0.6188, device='cuda:0')]\n",
      "INFO:root:epoch 1 stats for 21138 out of 32520 are : train: [2.023479449037279, tensor(0.7397, device='cuda:0'), tensor(0.8798, device='cuda:0'), tensor(0.6193, device='cuda:0')]\n",
      "INFO:root:epoch 1 stats for 22764 out of 32520 are : train: [2.016959686895976, tensor(0.7405, device='cuda:0'), tensor(0.8804, device='cuda:0'), tensor(0.6210, device='cuda:0')]\n",
      "INFO:root:epoch 1 stats for 24390 out of 32520 are : train: [2.0098276060885607, tensor(0.7410, device='cuda:0'), tensor(0.8809, device='cuda:0'), tensor(0.6214, device='cuda:0')]\n",
      "INFO:root:epoch 1 stats for 26016 out of 32520 are : train: [2.004385372222863, tensor(0.7413, device='cuda:0'), tensor(0.8814, device='cuda:0'), tensor(0.6218, device='cuda:0')]\n",
      "INFO:root:epoch 1 stats for 27642 out of 32520 are : train: [1.9985239569767022, tensor(0.7419, device='cuda:0'), tensor(0.8818, device='cuda:0'), tensor(0.6227, device='cuda:0')]\n",
      "INFO:root:epoch 1 stats for 29268 out of 32520 are : train: [1.995942267365382, tensor(0.7422, device='cuda:0'), tensor(0.8819, device='cuda:0'), tensor(0.6231, device='cuda:0')]\n",
      "INFO:root:epoch 1 stats for 30894 out of 32520 are : train: [1.9900007131239075, tensor(0.7427, device='cuda:0'), tensor(0.8827, device='cuda:0'), tensor(0.6237, device='cuda:0')]\n",
      "INFO:root:epoch 1 stats for 32520 out of 32520 are : train: [1.9832691731115177, tensor(0.7434, device='cuda:0'), tensor(0.8834, device='cuda:0'), tensor(0.6246, device='cuda:0')]\n",
      "INFO:root:saving model in models/2020-02-03_18_19_19.098081-albert-base-v2-accuracy-0.62-epoch-1-squad_ver-2.0\n"
     ]
    }
   ],
   "source": [
    "learn.fit(config.epochs,cbs=disc_lr_sched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T23:19:19.143403Z",
     "start_time": "2020-02-03T23:19:19.138769Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train: [1.9832691731115177, tensor(0.7434, device='cuda:0'), tensor(0.8834, device='cuda:0'), tensor(0.6246, device='cuda:0')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.qa_avg_stats.train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T23:19:19.158323Z",
     "start_time": "2020-02-03T23:19:19.144675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "valid: [3.032757637344821, tensor(0.6205, device='cuda:0'), tensor(0.8505, device='cuda:0'), tensor(0.4678, device='cuda:0')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.qa_avg_stats.valid_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T23:19:19.593756Z",
     "start_time": "2020-02-03T23:19:19.159529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T23:19:19.596863Z",
     "start_time": "2020-02-03T23:19:19.595008Z"
    }
   },
   "outputs": [],
   "source": [
    "# manually save and load model weights\n",
    "\n",
    "# save_model(learn,config.output_dir)\n",
    "# learn.model.load_state_dict(torch.load(config.output_dir/config.load_checkpoint/\"weights.bin\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T23:19:19.608325Z",
     "start_time": "2020-02-03T23:19:19.597780Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_raw_preds(learner):\n",
    "    learner(\"begin_epoch\")\n",
    "    with torch.no_grad(): \n",
    "        learner.dl = learner.data.valid_dl\n",
    "        yps = []\n",
    "        ybs = []\n",
    "        for i,(xb,yb) in enumerate(tqdm(learner.dl)):\n",
    "            learner.iter = i\n",
    "            learner.xb,learner.yb = xb,yb                      \n",
    "            learner('begin_batch')\n",
    "            ybs.append(yb)\n",
    "            yps.append(learner.model(learner.xb))\n",
    "    return yps, ybs\n",
    "\n",
    "yps,ybs = get_raw_preds(learn)\n",
    "\n",
    "preds = [(torch.stack([torch.argmax(si,1),torch.argmax(ei,1)],1),torch.argmax(poss,1)) for (si,ei,poss) in yps]\n",
    "\n",
    "p1,p2 = zip(*preds)\n",
    "\n",
    "p1,p2 = torch.cat(p1),torch.cat(p2)\n",
    "\n",
    "a1,a2 = zip(*ybs)\n",
    "a1,a2 = torch.cat(a1),torch.cat(a2)\n",
    "\n",
    "print(f\"accuracy for detecting {(a2.cuda()==p2).float().mean()}\"\n",
    "\n",
    "p1.shape\n",
    "\n",
    "p1[~a2.bool()]\n",
    "\n",
    "(  ((p1[:,0] == a1[:,0].cuda()).float().mean()) + ((p1[:,1] == a1[:,1].cuda()).float().mean()))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T23:27:41.093778Z",
     "start_time": "2020-02-03T23:27:41.083855Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_collate_x(samples, pad_idx=config.pad_idx, pad_first=False):\n",
    "    max_len = max([len(s[0]) for s in samples])\n",
    "    res = torch.zeros(len(samples), max_len).long() + pad_idx\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: res[i, -len(s[0]):] = torch.LongTensor(s[0])\n",
    "        else:         res[i, :len(s[0]) ] = torch.LongTensor(s[0])\n",
    "    return res\n",
    "\n",
    "def prep_text(text, question, tok):\n",
    "    tok_text, tok_ques = tok.tokenize(text), tok.tokenize(question) \n",
    "    truncate_len = 512 - len(tok_ques) - 3*3\n",
    "    res = [\"[CLS]\"] + tok_text[:truncate_len] + [\"[SEP]\"] + tok_ques + [\"[SEP]\"]\n",
    "    return torch.tensor(tok.convert_tokens_to_ids(res)).unsqueeze(0)\n",
    "\n",
    "def get_pred(texts, question, model, tok):\n",
    "    if texts == []: return \"could not find a section which matched query\",\"N/A\"\n",
    "    texts = listify(texts)\n",
    "    # 1. tokenize/encode the input text\n",
    "    input_ids = pad_collate_x([prep_text(t, question, tok) for t in texts])\n",
    "    # 2. extract the logits vector for the next possible token\n",
    "    outputs = model(input_ids.cuda())\n",
    "    logits,imp_logits = outputs[:2],outputs[2]\n",
    "    # 3. apply argmax to the logits so we have the probabilities of each index \n",
    "    (start_probs,starts),(end_probs,ends) = [torch.max(out, dim=1) for out in logits]\n",
    "    # 4. sort the sums of the starts and ends to determine which answers are the most ideal\n",
    "    sorted_sums = np.argsort([sp+ep for (sp,ep) in zip(start_probs,end_probs)])[::-1]\n",
    "    answerable = bool(torch.argmax(imp_logits,dim=1))\n",
    "    def _proc1(idx,start,end):\n",
    "        if start > end: return\n",
    "        elif start == end: end += 1\n",
    "        pred = tok.convert_ids_to_tokens(input_ids[idx][start:end])\n",
    "        return tok.convert_tokens_to_string(pred)\n",
    "    \n",
    "    # find the best answer\n",
    "    for i,s in enumerate(sorted_sums):\n",
    "        ans = _proc1(i,starts[i],ends[i])\n",
    "        if ans is not None and \"<pad>\" not in ans: return answerable, ans, texts[i]\n",
    "    return \"unanswerable\",texts[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T23:27:41.103550Z",
     "start_time": "2020-02-03T23:27:41.094859Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tests with samples \n",
    "sample1 = \"[CLS] there have been thirty earthquakes in the past three days. [SEP] how many earthquakes have there been? [SEP]\"\n",
    "sample2 = \"[CLS] the storm took place yesterday from dawn to dusk [SEP] what took place??\"\n",
    "sample3 = \"[CLS] No.2 pencils are used a lot in schools. [SEP] what are used?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T23:27:41.143878Z",
     "start_time": "2020-02-03T23:27:41.105913Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " 'thirty',\n",
       " '[CLS] there have been thirty earthquakes in the past three days. [SEP] how many earthquakes have there been? [SEP]')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pred([sample1],\"\",learn.model,tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
