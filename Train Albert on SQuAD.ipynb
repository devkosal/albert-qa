{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ALBERT for Question Answering - SQuAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updates:\n",
    "\n",
    "Things implemented:\n",
    "- Data Loading\n",
    "- Model\n",
    "- Learner\n",
    "- Prediction on new data\n",
    "- Optimizer selection\n",
    "- Segment IDs\n",
    "- F1 Score\n",
    "- Checkpoints\n",
    "- Use a more powerful machine to train\n",
    "- Gradient Accumulation\n",
    "- Squad 2.0\n",
    "    - Multi Task Learning Changes\n",
    "\n",
    "TODO:\n",
    "- Consider using the sliding window approach for long sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:24.282536Z",
     "start_time": "2020-02-02T22:33:23.339696Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src import *\n",
    "from transformers import AutoTokenizer, AlbertModel,AlbertPreTrainedModel\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "import collections\n",
    "from tqdm import tqdm, trange\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:24.286319Z",
     "start_time": "2020-02-02T22:33:24.284074Z"
    }
   },
   "outputs": [],
   "source": [
    "# logging.basicConfig()\n",
    "# logger = logging.getLogger()\n",
    "# logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:24.302505Z",
     "start_time": "2020-02-02T22:33:24.288157Z"
    }
   },
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    data_path = Path(\"../data/SQuAD/2.0\"), # replace with the directory containing the parsed csv files\n",
    "    output_dir = Path(\"./checkpoints\"), # for storing model weights between epochs\n",
    "    task = \"SQuAD\",\n",
    "    squad_version = \"2.0\",\n",
    "    testing=False,\n",
    "    seed = 2020,\n",
    "    model = 'albert-base-v2',\n",
    "    max_lr=3e-5,\n",
    "    max_lr_last = 3e-4,\n",
    "    phases = .3,\n",
    "    optimizer=\"lamb\", # choose between 'adam' or 'lamb'\n",
    "    epochs=1,\n",
    "    use_fp16=False,\n",
    "    recreate_ds=False,\n",
    "    bs=4, \n",
    "    effective_bs=4, # set this different from bs to determine gradient accumulation steps (i.e. effective_bs/bs)\n",
    "    max_seq_len=512,\n",
    "    start_tok = \"[CLS]\",\n",
    "    end_tok = \"[SEP]\",\n",
    "    sep_tok = \"[SEP]\",\n",
    "    unk_tok_idx=1,\n",
    "    sep_idx=3,\n",
    "    pad_idx=0,\n",
    "    feat_cols = [\"question\",\"paragraph\"],\n",
    "    label_cols = [\"idxs\",\"is_impossible\"],\n",
    "    adjustment = 2,\n",
    "    save_checkpoint = True,\n",
    "    load_checkpoint=\"2020-02-02_17_12_56.448216-albert-base-v2-accuracy-0.62-epoch-0-squad_ver-2.0\"\n",
    ")\n",
    "\n",
    "config.model_name = re.findall(r\"(.+?)-\",config.model)[0]\n",
    "\n",
    "# set optimizer\n",
    "assert config.optimizer.lower() in [\"adam\",\"lamb\"], f\"invalid optimizer in config {config.optimizer}\"\n",
    "config.opt_func = lamb_opt() if config.optimizer.lower() == \"lamb\" else adam_opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:24.312220Z",
     "start_time": "2020-02-02T22:33:24.304067Z"
    }
   },
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def remove_max_sl(df):\n",
    "    init_len = len(df)\n",
    "    df = df[df.seq_len < config.max_seq_len-2]\n",
    "    new_len = len(df)\n",
    "    print(f\"dropping {init_len - new_len} out of {init_len} questions\")\n",
    "    return df\n",
    "\n",
    "def str2tensor(s):\n",
    "    indices = re.findall(\"-?\\d+\",s)\n",
    "    return torch.tensor([int(indices[0]), int(indices[1])], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:25.311313Z",
     "start_time": "2020-02-02T22:33:24.313582Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(config.data_path/f\"train_{config.squad_version}_{config.model_name}.csv\")\n",
    "valid = pd.read_csv(config.data_path/f\"val_{config.squad_version}_{config.model_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:25.598336Z",
     "start_time": "2020-02-02T22:33:25.312748Z"
    }
   },
   "outputs": [],
   "source": [
    "train.drop_duplicates(inplace=True)\n",
    "valid.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:25.659412Z",
     "start_time": "2020-02-02T22:33:25.599652Z"
    }
   },
   "outputs": [],
   "source": [
    "# randomizing the order of training data\n",
    "train = train.sample(frac=1).reset_index(drop=True) #random_state = config.seed\n",
    "valid = valid.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:25.674055Z",
     "start_time": "2020-02-02T22:33:25.662181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False    0.66617\n",
       " True     0.33383\n",
       " Name: is_impossible, dtype: float64, False    0.636592\n",
       " True     0.363408\n",
       " Name: is_impossible, dtype: float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.is_impossible.value_counts(normalize=True), valid.is_impossible.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:25.679060Z",
     "start_time": "2020-02-02T22:33:25.676184Z"
    }
   },
   "outputs": [],
   "source": [
    "# reduce df sizes if testing\n",
    "if config.testing:\n",
    "    train = train[:int(len(train)/20)]\n",
    "    valid = valid[:int(len(valid)/20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:25.704976Z",
     "start_time": "2020-02-02T22:33:25.680556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping 216 out of 130294 questions\n",
      "dropping 124 out of 16315 questions\n"
     ]
    }
   ],
   "source": [
    "train, valid = remove_max_sl(train), remove_max_sl(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:25.708623Z",
     "start_time": "2020-02-02T22:33:25.706505Z"
    }
   },
   "outputs": [],
   "source": [
    "# train[\"idxs\"] = train.apply(lambda row: row[\"idxs\"] if not row[\"is_impossible\"] else '[-2, -2]',axis=1)\n",
    "# valid[\"idxs\"] = valid.apply(lambda row: row[\"idxs\"] if not row[\"is_impossible\"] else '[-2, -2]',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:25.720826Z",
     "start_time": "2020-02-02T22:33:25.710156Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>answer</th>\n",
       "      <th>idxs</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>ans_text</th>\n",
       "      <th>is_impossible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What sources are Avicenna based on?</td>\n",
       "      <td>Islamic political philosophy, was, indeed, roo...</td>\n",
       "      <td>['▁qur', \"'\", 'an', '▁and', '▁the', '▁sun', 'n...</td>\n",
       "      <td>[31, 45]</td>\n",
       "      <td>331</td>\n",
       "      <td>Qur'an and the Sunnah, the words and practices...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why does a transistor increase a signal?</td>\n",
       "      <td>A transistor is a semiconductor device used to...</td>\n",
       "      <td>['▁the', '▁controlled', '▁', '(', 'out', 'put'...</td>\n",
       "      <td>[72, 92]</td>\n",
       "      <td>122</td>\n",
       "      <td>the controlled (output) power can be higher th...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When was the last criminal part of copyright l...</td>\n",
       "      <td>The first criminal provision in U.S. copyright...</td>\n",
       "      <td>['▁1897']</td>\n",
       "      <td>[31, 32]</td>\n",
       "      <td>199</td>\n",
       "      <td>1897</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many U.S. investment banks significantly i...</td>\n",
       "      <td>From 2004 to 2007, the top five U.S. investmen...</td>\n",
       "      <td>['▁five']</td>\n",
       "      <td>[25, 26]</td>\n",
       "      <td>235</td>\n",
       "      <td>five</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What facilities house the  George Warren Brown...</td>\n",
       "      <td>With roots dating back to 1909 in the universi...</td>\n",
       "      <td>['▁brown', '▁and', '▁gold', 'far', 'b', '▁halls']</td>\n",
       "      <td>[188, 194]</td>\n",
       "      <td>255</td>\n",
       "      <td>Brown and Goldfarb Halls</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                What sources are Avicenna based on?   \n",
       "1           Why does a transistor increase a signal?   \n",
       "2  When was the last criminal part of copyright l...   \n",
       "3  How many U.S. investment banks significantly i...   \n",
       "4  What facilities house the  George Warren Brown...   \n",
       "\n",
       "                                           paragraph  \\\n",
       "0  Islamic political philosophy, was, indeed, roo...   \n",
       "1  A transistor is a semiconductor device used to...   \n",
       "2  The first criminal provision in U.S. copyright...   \n",
       "3  From 2004 to 2007, the top five U.S. investmen...   \n",
       "4  With roots dating back to 1909 in the universi...   \n",
       "\n",
       "                                              answer        idxs  seq_len  \\\n",
       "0  ['▁qur', \"'\", 'an', '▁and', '▁the', '▁sun', 'n...    [31, 45]      331   \n",
       "1  ['▁the', '▁controlled', '▁', '(', 'out', 'put'...    [72, 92]      122   \n",
       "2                                          ['▁1897']    [31, 32]      199   \n",
       "3                                          ['▁five']    [25, 26]      235   \n",
       "4  ['▁brown', '▁and', '▁gold', 'far', 'b', '▁halls']  [188, 194]      255   \n",
       "\n",
       "                                            ans_text  is_impossible  \n",
       "0  Qur'an and the Sunnah, the words and practices...           True  \n",
       "1  the controlled (output) power can be higher th...          False  \n",
       "2                                               1897           True  \n",
       "3                                               five          False  \n",
       "4                           Brown and Goldfarb Halls          False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:25.730128Z",
     "start_time": "2020-02-02T22:33:25.722408Z"
    }
   },
   "outputs": [],
   "source": [
    "class TokenizerProcessor(Processor):\n",
    "    def __init__(self, tok_func, max_sl, start_tok, end_tok, pre_rules=None,post_rules=None):\n",
    "        self.tok_func,self.max_sl = tok_func,max_sl\n",
    "        self.pre_rules,self.post_rules=pre_rules,post_rules\n",
    "        self.start_tok, self.end_tok = start_tok, end_tok\n",
    "\n",
    "    def proc1(self, x): return [self.start_tok] + self.tok_func(x)[:self.max_sl-2] + [self.end_tok]\n",
    "    \n",
    "    def __call__(self, items): return tqdm([self.proc1(x) for x in items])\n",
    "\n",
    "class NumericalizeProcessor(Processor):\n",
    "    \"\"\"\n",
    "    only works with an existing vocab at the moment and min_freq is not accounted for\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab:dict, unk_tok_idx:int, min_freq=2): \n",
    "        self.vocab, self.unk_tok_idx, self.min_freq = vocab, unk_tok_idx, min_freq\n",
    "    \n",
    "    def proc1(self, x): return [self.vocab[i] if i in self.vocab else self.unk_tok_idx for i in x]\n",
    "    \n",
    "    def __call__(self, items): \n",
    "        if getattr(self, 'otoi', None) is None:\n",
    "            self.otoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.vocab)})\n",
    "        return tqdm([self.proc1(x) for x in items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:26.045239Z",
     "start_time": "2020-02-02T22:33:25.731603Z"
    }
   },
   "outputs": [],
   "source": [
    "tok = AutoTokenizer.from_pretrained(config.model)\n",
    "proc_tok = TokenizerProcessor(tok.tokenize, config.max_seq_len, config.start_tok, config.end_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:26.079189Z",
     "start_time": "2020-02-02T22:33:26.046587Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab = {tok.convert_ids_to_tokens(i):i for i in range(tok.vocab_size)}\n",
    "proc_num = NumericalizeProcessor(vocab, unk_tok_idx=config.unk_tok_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:26.094717Z",
     "start_time": "2020-02-02T22:33:26.080678Z"
    }
   },
   "outputs": [],
   "source": [
    "class QALabelProcessor(Processor):\n",
    "    def __init__(self, parse_func = noop, adjustment = 2):\n",
    "        self.parse_func = parse_func\n",
    "        self.adjustment = adjustment\n",
    "        self.vocab=[False, True]\n",
    "        self.otoi=None\n",
    "        \n",
    "    def cat_proc1(self,item): return self.otoi[item]\n",
    "    def index_proc1(self, item): return self.parse_func(item) + self.adjustment\n",
    "    \n",
    "    def __call__(self, items): \n",
    "        if self.otoi is None:\n",
    "            self.otoi  = {v:k for k,v in enumerate(self.vocab)}\n",
    "        return [(self.index_proc1(item[0]),self.cat_proc1(item[1])) for item in items] # we want the \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:26.104016Z",
     "start_time": "2020-02-02T22:33:26.096006Z"
    }
   },
   "outputs": [],
   "source": [
    "proc_qa = QALabelProcessor(str2tensor,config.adjustment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:26.113260Z",
     "start_time": "2020-02-02T22:33:26.105481Z"
    }
   },
   "outputs": [],
   "source": [
    "class SquadTextList(ItemList):      \n",
    "    @classmethod  \n",
    "    def from_df(cls, df, feat_cols, label_cols, sep_tok, test=False):\n",
    "        feat_cols = listify(feat_cols)\n",
    "        x = df[feat_cols[0]]\n",
    "        for i in range(1,len(feat_cols)):\n",
    "            x += f\" {sep_tok} \" + df[feat_cols[i]]\n",
    "        labels = cls(df[label_cols].values) if not test else cls([[None,None] for _ in len(df)])\n",
    "        return cls(x,labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:32.851753Z",
     "start_time": "2020-02-02T22:33:26.114405Z"
    }
   },
   "outputs": [],
   "source": [
    "if (not (config.data_path/f\"squad_{config.squad_version}_data_trn.pkl\").exists()) or config.recreate_ds or config.testing:\n",
    "    il_train = SquadTextList.from_df(train,config.feat_cols,config.label_cols,config.sep_tok)\n",
    "    il_valid = SquadTextList.from_df(valid,config.feat_cols,config.label_cols,config.sep_tok)\n",
    "\n",
    "    ll_valid = LabeledData(il_valid,il_valid.labels,proc_x = [proc_tok,proc_num], proc_y=[proc_qa])\n",
    "    ll_train = LabeledData(il_train,il_train.labels,proc_x = [proc_tok,proc_num], proc_y=[proc_qa])\n",
    "\n",
    "    # saving/loading presaved data if not testing\n",
    "    if not config.testing:\n",
    "        # save an object\n",
    "        pickle.dump(ll_train, open( config.data_path/f\"squad_{config.squad_version}_data_trn.pkl\", \"wb\" ) )\n",
    "        pickle.dump(ll_valid, open( config.data_path/f\"squad_{config.squad_version}_data_val.pkl\", \"wb\" ) )\n",
    "else:\n",
    "    # load an object\n",
    "    ll_train = pickle.load( open( config.data_path/f\"squad_{config.squad_version}_data_trn.pkl\", \"rb\" ) )\n",
    "    ll_valid = pickle.load( open( config.data_path/f\"squad_{config.squad_version}_data_val.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:32.856299Z",
     "start_time": "2020-02-02T22:33:32.852942Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Sampler\n",
    "\n",
    "class SortSampler(Sampler):\n",
    "    def __init__(self, data_source, key): self.data_source,self.key = data_source,key\n",
    "    def __len__(self): return len(self.data_source)\n",
    "    def __iter__(self):\n",
    "        return iter(sorted(list(range(len(self.data_source))), key=self.key, reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:32.868594Z",
     "start_time": "2020-02-02T22:33:32.857530Z"
    }
   },
   "outputs": [],
   "source": [
    "class SortishSampler(Sampler):\n",
    "    def __init__(self, data_source, key, bs):\n",
    "        self.data_source,self.key,self.bs = data_source,key,bs\n",
    "\n",
    "    def __len__(self) -> int: return len(self.data_source)\n",
    "\n",
    "    def __iter__(self):\n",
    "        idxs = torch.randperm(len(self.data_source))\n",
    "        megabatches = [idxs[i:i+self.bs*50] for i in range(0, len(idxs), self.bs*50)]\n",
    "        sorted_idx = torch.cat([tensor(sorted(s, key=self.key, reverse=True)) for s in megabatches])\n",
    "        batches = [sorted_idx[i:i+self.bs] for i in range(0, len(sorted_idx), self.bs)]\n",
    "        max_idx = torch.argmax(tensor([self.key(ck[0]) for ck in batches]))  # find the chunk with the largest key,\n",
    "        batches[0],batches[max_idx] = batches[max_idx],batches[0]            # then make sure it goes first.\n",
    "        batch_idxs = torch.randperm(len(batches)-2)\n",
    "        sorted_idx = torch.cat([batches[i+1] for i in batch_idxs]) if len(batches) > 1 else LongTensor([])\n",
    "        sorted_idx = torch.cat([batches[0], sorted_idx, batches[-1]])\n",
    "        return iter(sorted_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:32.877442Z",
     "start_time": "2020-02-02T22:33:32.869837Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_collate_qa(samples, pad_idx=config.pad_idx, pad_first=False):\n",
    "    max_len = max([len(s[0]) for s in samples])\n",
    "    res = torch.zeros(len(samples), max_len).long() + pad_idx\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: res[i, -len(s[0]):] = torch.LongTensor(s[0])\n",
    "        else:         res[i, :len(s[0]) ] = torch.LongTensor(s[0])\n",
    "    qa_idxs = torch.cat([s[1][0].unsqueeze(0) for s in samples])\n",
    "    imp_labels = torch.tensor([s[1][1] for s in samples])\n",
    "    return res, (qa_idxs, imp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:32.886871Z",
     "start_time": "2020-02-02T22:33:32.880078Z"
    }
   },
   "outputs": [],
   "source": [
    "train_sampler = SortishSampler(ll_train.x, key=lambda t: len(ll_train[int(t)][0]), bs=config.bs)\n",
    "train_dl = DataLoader(ll_train, batch_size=config.bs, sampler=train_sampler, collate_fn=pad_collate_qa)\n",
    "\n",
    "valid_sampler = SortSampler(ll_valid.x, key=lambda t: len(ll_valid[int(t)][0]))\n",
    "valid_dl = DataLoader(ll_valid, batch_size=config.bs, sampler=valid_sampler, collate_fn=pad_collate_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:32.895810Z",
     "start_time": "2020-02-02T22:33:32.888388Z"
    }
   },
   "outputs": [],
   "source": [
    "# x,y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:32.904777Z",
     "start_time": "2020-02-02T22:33:32.896852Z"
    }
   },
   "outputs": [],
   "source": [
    "data = DataBunch(train_dl,valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:32.914364Z",
     "start_time": "2020-02-02T22:33:32.905915Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_segments(x,sep_idx=config.sep_idx):\n",
    "    res = x.new_zeros(x.size())\n",
    "    for row_idx, row in enumerate(x):\n",
    "        in_seg_1 = False\n",
    "        for val_idx,val in enumerate(row):\n",
    "            if val == sep_idx:\n",
    "                in_seg_1 = True\n",
    "            if in_seg_1: \n",
    "                res[row_idx,val_idx] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:32.926213Z",
     "start_time": "2020-02-02T22:33:32.915567Z"
    }
   },
   "outputs": [],
   "source": [
    "weights = config.output_dir/config.load_checkpoint if config.load_checkpoint else config.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:32.932944Z",
     "start_time": "2020-02-02T22:33:32.927388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-02-02_17_12_56.448216-albert-base-v2-accuracy-0.62-epoch-0-squad_ver-2.0'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:32.943140Z",
     "start_time": "2020-02-02T22:33:32.934098Z"
    }
   },
   "outputs": [],
   "source": [
    "class AlbertForQuestionAnswering(AlbertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.albert = AlbertModel(config)\n",
    "        self.qa_outputs = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        start_positions=None,\n",
    "        end_positions=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        start_positions (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`, defaults to :obj:`None`):\n",
    "            Labels for position (index) of the start of the labelled span for computing the token classification loss.\n",
    "            Positions are clamped to the length of the sequence (`sequence_length`).\n",
    "            Position outside of the sequence are not taken into account for computing the loss.\n",
    "        end_positions (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`, defaults to :obj:`None`):\n",
    "            Labels for position (index) of the end of the labelled span for computing the token classification loss.\n",
    "            Positions are clamped to the length of the sequence (`sequence_length`).\n",
    "            Position outside of the sequence are not taken into account for computing the loss.\n",
    "    Returns:\n",
    "        :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.AlbertConfig`) and inputs:\n",
    "        loss: (`optional`, returned when ``labels`` is provided) ``torch.FloatTensor`` of shape ``(1,)``:\n",
    "            Total span extraction loss is the sum of a Cross-Entropy for the start and end positions.\n",
    "        start_scores ``torch.FloatTensor`` of shape ``(batch_size, sequence_length,)``\n",
    "            Span-start scores (before SoftMax).\n",
    "        end_scores: ``torch.FloatTensor`` of shape ``(batch_size, sequence_length,)``\n",
    "            Span-end scores (before SoftMax).\n",
    "        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n",
    "            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n",
    "            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n",
    "            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
    "        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n",
    "            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape\n",
    "            :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n",
    "            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
    "            heads.\n",
    "    Examples::\n",
    "        # The checkpoint albert-base-v2 is not fine-tuned for question answering. Please see the\n",
    "        # examples/run_squad.py example to see how to fine-tune a model to a question answering task.\n",
    "        from transformers import AlbertTokenizer, AlbertForQuestionAnswering\n",
    "        import torch\n",
    "        tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "        model = AlbertForQuestionAnswering.from_pretrained('albert-base-v2')\n",
    "        question, text = \"Who was Jim Henson?\", \"Jim Henson was a nice puppet\"\n",
    "        input_dict = tokenizer.encode_plus(question, text, return_tensors='pt')\n",
    "        start_scores, end_scores = model(**input_dict)\n",
    "        \"\"\"\n",
    "\n",
    "        outputs = self.albert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "\n",
    "        sequence_output, pooled_output = outputs[:2]\n",
    "\n",
    "        logits = self.qa_outputs(sequence_output)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "\n",
    "        outputs = (start_logits, end_logits,) + outputs[2:]\n",
    "        if start_positions is not None and end_positions is not None:\n",
    "            # If we are on multi-GPU, split add a dimension\n",
    "            if len(start_positions.size()) > 1:\n",
    "                start_positions = start_positions.squeeze(-1)\n",
    "            if len(end_positions.size()) > 1:\n",
    "                end_positions = end_positions.squeeze(-1)\n",
    "            # sometimes the start/end positions are outside our model inputs, we ignore these terms\n",
    "            ignored_index = start_logits.size(1)\n",
    "            start_positions.clamp_(0, ignored_index)\n",
    "            end_positions.clamp_(0, ignored_index)\n",
    "\n",
    "            loss_fct = CrossEntropyLoss(ignore_index=ignored_index)\n",
    "            start_loss = loss_fct(start_logits, start_positions)\n",
    "            end_loss = loss_fct(end_logits, end_positions)\n",
    "            total_loss = (start_loss + end_loss) / 2\n",
    "            outputs = (total_loss,) + outputs\n",
    "\n",
    "        return outputs + (pooled_output,)  # (loss), start_logits, end_logits, (hidden_states), (attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:32.950173Z",
     "start_time": "2020-02-02T22:33:32.944290Z"
    }
   },
   "outputs": [],
   "source": [
    "class AlbertForQuestionAnsweringMTL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlbertForQuestionAnsweringMTL,self).__init__()\n",
    "        self.bert = AlbertForQuestionAnswering.from_pretrained(config.model)\n",
    "        self.bert.train()\n",
    "        self.poss = nn.Linear(768,2)\n",
    "        \n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):       \n",
    "        token_type_ids = set_segments(input_ids)\n",
    "        outputs = self.bert(input_ids,token_type_ids=token_type_ids)\n",
    "        poss_outputs = self.poss(outputs[2])#torch.randn(config.bs,2,device=\"cuda\")\n",
    "        return outputs[:2] + (poss_outputs,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:32.956790Z",
     "start_time": "2020-02-02T22:33:32.951375Z"
    }
   },
   "outputs": [],
   "source": [
    "# class AlbertForQuestionAnsweringMTL(AlbertPreTrainedModel):\n",
    "#     def __init__(self, config):\n",
    "#         super().__init__(config)\n",
    "#         self.num_labels = config.num_labels\n",
    "\n",
    "#         self.bert = AlbertModel(config)\n",
    "#         self.qa_outputs = nn.Linear(config.hidden_size, config.num_labels)\n",
    "#         self.imp_outputs = nn.Linear(config.hidden_size, 2)\n",
    "#         self.imp_dropout = nn.Dropout(.1)\n",
    "#         self.init_weights()\n",
    "#         self.train()\n",
    "\n",
    "#     def forward(self, input_ids=None, token_type_ids=None, position_ids=None):\n",
    "\n",
    "#         bert_outputs = self.bert(input_ids=input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "\n",
    "#         sequence_output = bert_outputs[0]\n",
    "#         pooled_output = bert_outputs[1]\n",
    "\n",
    "\n",
    "#         logits_qa = self.qa_outputs(sequence_output)\n",
    "#         start_logits, end_logits = logits_qa.split(1, dim=-1)\n",
    "#         start_logits = start_logits.squeeze(-1)\n",
    "#         end_logits = end_logits.squeeze(-1)\n",
    "    \n",
    "#         imp_logits = self.imp_outputs(self.imp_dropout(pooled_output))\n",
    "\n",
    "#         outputs = (start_logits, end_logits, imp_logits,)\n",
    "#         return outputs  # start_logits, end_logits, (hidden_states), (attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:33.773953Z",
     "start_time": "2020-02-02T22:33:32.957994Z"
    }
   },
   "outputs": [],
   "source": [
    "model = AlbertForQuestionAnsweringMTL()#.from_pretrained(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function and Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:33.777248Z",
     "start_time": "2020-02-02T22:33:33.775031Z"
    }
   },
   "outputs": [],
   "source": [
    "def assert_no_negs(tensor):\n",
    "    assert torch.all(torch.eq(tensor, abs(tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:33.792539Z",
     "start_time": "2020-02-02T22:33:33.778425Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining the loss function\n",
    "# defining the loss function\n",
    "def cross_entropy_qa_mtl(input, target):\n",
    "    \"\"\"\n",
    "    Summing the cross entropy loss from the starting and ending indices. \n",
    "    \"\"\"\n",
    "    loss = torch.add(F.cross_entropy(input[0], target[0][:,0]) , F.cross_entropy(input[1], target[0][:,1]))\n",
    "    poss_loss = F.cross_entropy(input[2], target[1])\n",
    "    return torch.add(loss, poss_loss)\n",
    "\n",
    "# def cross_entropy_qa_mtl(input, target):\n",
    "#     \"\"\"\n",
    "#     Summing the cross entropy loss from the starting and ending indices. \n",
    "#     \"\"\"\n",
    "#     assert_no_negs(target[0])\n",
    "#     assert_no_negs(target[1])\n",
    "    \n",
    "#     mask = (~target[1].bool()).float()\n",
    "#     qa_loss = torch.add(F.cross_entropy(input[0], target[0][:,0], reduction=\"none\"),\\\n",
    "#                         F.cross_entropy(input[1], target[0][:,1], reduction=\"none\"))/2.0\n",
    "#     qa_loss.mul_(mask+1)\n",
    "#     wtd_qa_loss = qa_loss.mean()\n",
    "\n",
    "#     imp_loss = F.cross_entropy(input[2], target[1])\n",
    "    \n",
    "#     loss = torch.add(wtd_qa_loss, imp_loss)\n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:33.803918Z",
     "start_time": "2020-02-02T22:33:33.793721Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining the evaluation metrics based on squad evaluation method\n",
    "def acc_qa(input,target,xb):\n",
    "    \"\"\"\n",
    "    Taking the average between the accuracies of predicting the start and ending indices\n",
    "    \"\"\"\n",
    "    return (accuracy(input[0], target[0][:,0]) + accuracy(input[1], target[0][:,1]))/2.0\n",
    "\n",
    "def acc_imp(input,target,xb):\n",
    "    return accuracy(input[2], target[1])\n",
    "\n",
    "def exact_match(input,target,xb):\n",
    "    def _acc(out, yb): return (torch.argmax(out, dim=1)==yb).float()\n",
    "    return (_acc(input[0], target[0][:,0]) + _acc(input[1], target[0][:,1]) == 2).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:33.813927Z",
     "start_time": "2020-02-02T22:33:33.805341Z"
    }
   },
   "outputs": [],
   "source": [
    "def f1_score(input,target,xb):\n",
    "    \"\"\"\n",
    "    based on the official evaluation script:\n",
    "    https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/\n",
    "    \"\"\"\n",
    "    pred_starts,pred_ends = [torch.argmax(out, dim=1) for out in input[:2]]\n",
    "    gold_starts,gold_ends = target[0][:,0], target[0][:,1]\n",
    "    \n",
    "    def _get_toks(idx,start,end):\n",
    "        if start == end: end += 1\n",
    "        return xb[idx][start:end]\n",
    "    \n",
    "    def _score1(pred_toks,gold_toks):\n",
    "        common = collections.Counter(gold_toks.tolist()) & collections.Counter(pred_toks.tolist())\n",
    "        num_same = sum(common.values())\n",
    "        if num_same == 0: \n",
    "            return 0\n",
    "        precision = 1.0 * num_same / len(pred_toks)\n",
    "        recall = 1.0 * num_same / len(gold_toks)\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "        return f1\n",
    "    \n",
    "    pred_toks = [_get_toks(i,start,end) for i,(start,end) in enumerate(zip(pred_starts,pred_ends))]\n",
    "    gold_toks = [_get_toks(i,start,end) for i,(start,end) in enumerate(zip(gold_starts,gold_ends))]\n",
    "    score = np.mean([_score1(pred,gold) for pred,gold in zip(pred_toks,gold_toks)])\n",
    "    return score             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:52.319753Z",
     "start_time": "2020-02-02T22:33:52.311570Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(learner,output_dir: Path):\n",
    "    def _create_dir(dirc):\n",
    "        if not os.path.exists(dirc): os.mkdir(dirc)\n",
    "    epoch = learner.epoch\n",
    "    metric = round(float(learner.qa_avg_stats.valid_stats.avg_stats[1]),2)\n",
    "    _create_dir(output_dir)\n",
    "    model_dir = f\"{re.sub(r'[ :]+','_',str(datetime.now()))}-{config.model}-accuracy-{metric}-epoch-{epoch}-squad_ver-{config.squad_version}\"\n",
    "    _create_dir(output_dir/model_dir)\n",
    "    st = learner.model.state_dict()\n",
    "    logging.info(f\"saving model in {output_dir/model_dir}\")\n",
    "    torch.save(st,output_dir/model_dir/\"weights.bin\") \n",
    "\n",
    "class SaveModelCallback(Callback):\n",
    "    def __init__(self,save_model_func,output_dir):\n",
    "        self.output_dir, self.save_model_func = output_dir,save_model_func\n",
    "    def after_epoch(self):\n",
    "        self.save_model_func(self, self.output_dir)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:52.331554Z",
     "start_time": "2020-02-02T22:33:52.320854Z"
    }
   },
   "outputs": [],
   "source": [
    "class CudaCallbackMTL(Callback):\n",
    "    def begin_fit(self): self.model.cuda()\n",
    "    def begin_batch(self): self.run.xb, self.run.yb = \\\n",
    "        self.xb.cuda(), (self.run.yb[0].cuda(), self.run.yb[1].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:52.338276Z",
     "start_time": "2020-02-02T22:33:52.333661Z"
    }
   },
   "outputs": [],
   "source": [
    "# gradient accumulation\n",
    "class GradientAccumulation(Callback):\n",
    "    _order=2\n",
    "    def __init__(self,bs,effective_bs):\n",
    "        self.bs, self.effective_bs = bs, effective_bs\n",
    "    def after_loss(self):\n",
    "        self.loss.div_(self.effective_bs/self.bs)\n",
    "    def after_backward(self):\n",
    "        if self.n_iter*self.bs % self.effective_bs != 0: raise CancelBatchException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:52.345555Z",
     "start_time": "2020-02-02T22:33:52.340058Z"
    }
   },
   "outputs": [],
   "source": [
    "class QAAvgStats(AvgStats):\n",
    "    def accumulate(self, run):\n",
    "        bn = run.xb.shape[0]\n",
    "        self.tot_loss += run.loss * bn\n",
    "        self.count += bn\n",
    "        for i,m in enumerate(self.metrics):\n",
    "            self.tot_mets[i] += m(run.pred, run.yb, run.xb) * bn\n",
    "            \n",
    "class QAAvgStatsCallback(AvgStatsCallback):\n",
    "    def __init__(self, metrics):\n",
    "        self.train_stats,self.valid_stats = QAAvgStats(metrics,True),QAAvgStats(metrics,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:52.353042Z",
     "start_time": "2020-02-02T22:33:52.347234Z"
    }
   },
   "outputs": [],
   "source": [
    "class MidStatsCallback(Callback):\n",
    "    _order=5\n",
    "    def __init__(self, update_freq_pct=.05):\n",
    "        self.update_freq_pct = update_freq_pct\n",
    "        logging.basicConfig()\n",
    "        self.logger = logging.getLogger()\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.update_freq = int(self.update_freq_pct*len(self.dl))\n",
    "        \n",
    "    def after_batch(self):\n",
    "        if self.n_iter % self.update_freq == 0:\n",
    "            stats = learn.qa_avg_stats.train_stats if self.in_train else learn.qa_avg_stats.valid_stats\n",
    "            self.logger.info(f\"epoch {self.epoch} stats for {self.n_iter} out of {self.iters} are : {stats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:52.364917Z",
     "start_time": "2020-02-02T22:33:52.354642Z"
    }
   },
   "outputs": [],
   "source": [
    "cbfs = [partial(QAAvgStatsCallback,[acc_qa,acc_imp,exact_match]),#,exact_match,,f1_score]),\n",
    "        CudaCallbackMTL,\n",
    "        ProgressCallback,\n",
    "        Recorder,\n",
    "        MidStatsCallback]\n",
    "\n",
    "if not config.testing and config.save_checkpoint: \n",
    "    cbfs.append(partial(SaveModelCallback,save_model,config.output_dir))\n",
    "    \n",
    "if config.effective_bs and config.bs != config.effective_bs:\n",
    "    cbfs.append(partial(GradientAccumulation,config.bs,config.effective_bs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:52.374701Z",
     "start_time": "2020-02-02T22:33:52.366570Z"
    }
   },
   "outputs": [],
   "source": [
    "def albert_splitter(m, g1=[],g2=[]):\n",
    "    l = list(dict(m.named_children()).keys())\n",
    "    if \"qa_outputs\" in  l: g2+= m.qa_outputs.parameters()\n",
    "    if \"imp_outputs\" in l: g2+= m.imp_outputs.parameters()\n",
    "    if isinstance(m,torch.nn.modules.normalization.LayerNorm):\n",
    "        g1+= m.parameters()\n",
    "    elif hasattr(m, 'weight'): \n",
    "        g1+= m.parameters()\n",
    "    for ll in m.children(): albert_splitter(ll, g1, g2)\n",
    "    return g1,g2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:52.384953Z",
     "start_time": "2020-02-02T22:33:52.376312Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/fastai/course-v3/blob/master/nbs/dl2/11_train_imagenette.ipynb\n",
    "def create_phases(phases):\n",
    "    phases = listify(phases)\n",
    "    return phases + [1-sum(phases)]\n",
    "\n",
    "# https://github.com/fastai/course-v3/blob/master/nbs/dl2/11a_transfer_learning.ipynb\n",
    "def sched_1cycle(lrs, pct_start=0.3, mom_start=0.95, mom_mid=0.85, mom_end=0.95):\n",
    "    phases = create_phases(pct_start)\n",
    "    sched_lr  = [combine_scheds(phases, cos_1cycle_anneal(lr/10., lr, lr/1e5))\n",
    "                 for lr in lrs]\n",
    "    sched_mom = combine_scheds(phases, cos_1cycle_anneal(mom_start, mom_mid, mom_end))\n",
    "    return [ParamScheduler('lr', sched_lr),\n",
    "            ParamScheduler('mom', sched_mom)]\n",
    "\n",
    "disc_lr_sched = sched_1cycle([config.max_lr,config.max_lr_last], config.phases) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:52.396494Z",
     "start_time": "2020-02-02T22:33:52.387485Z"
    }
   },
   "outputs": [],
   "source": [
    "# the learning rate we apply here does not matter since we are scheduling \n",
    "learn = Learner(model, data, cross_entropy_qa_mtl,lr=config.max_lr,cb_funcs=cbfs,splitter=albert_splitter\\\n",
    "                ,opt_func=config.opt_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:33:53.545135Z",
     "start_time": "2020-02-02T22:33:52.398257Z"
    }
   },
   "outputs": [],
   "source": [
    "if config.load_checkpoint:\n",
    "    learn.model.load_state_dict(torch.load(config.output_dir/config.load_checkpoint/\"weights.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-02T22:33:52.204Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc_qa</th>\n",
       "      <th>train_acc_imp</th>\n",
       "      <th>train_exact_match</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_acc_qa</th>\n",
       "      <th>valid_acc_imp</th>\n",
       "      <th>valid_exact_match</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='318' class='' max='32520', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.98% [318/32520 01:34<2:39:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1,cbs=disc_lr_sched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-02T22:33:52.205Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.qa_avg_stats.train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-02T22:33:52.207Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.qa_avg_stats.valid_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-02T22:33:52.208Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-02T22:33:52.210Z"
    }
   },
   "outputs": [],
   "source": [
    "# manually save and load model weights\n",
    "\n",
    "# save_model(learn,config.output_dir)\n",
    "# learn.model.load_state_dict(torch.load(config.output_dir/config.load_checkpoint/\"weights.bin\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-02T22:33:52.212Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_collate_x(samples, pad_idx=config.pad_idx, pad_first=False):\n",
    "    max_len = max([len(s[0]) for s in samples])\n",
    "    res = torch.zeros(len(samples), max_len).long() + pad_idx\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: res[i, -len(s[0]):] = torch.LongTensor(s[0])\n",
    "        else:         res[i, :len(s[0]) ] = torch.LongTensor(s[0])\n",
    "    return res\n",
    "\n",
    "def prep_text(text, question, tok):\n",
    "    tok_text, tok_ques = tok.tokenize(text), tok.tokenize(question) \n",
    "    truncate_len = 512 - len(tok_ques) - 3*3\n",
    "    res = [\"[CLS]\"] + tok_text[:truncate_len] + [\"[SEP]\"] + tok_ques + [\"[SEP]\"]\n",
    "    return torch.tensor(tok.convert_tokens_to_ids(res)).unsqueeze(0)\n",
    "\n",
    "def get_pred(texts, question, model, tok):\n",
    "    if texts == []: return \"could not find a section which matched query\",\"N/A\"\n",
    "    texts = listify(texts)\n",
    "    # 1. tokenize/encode the input text\n",
    "    input_ids = pad_collate_x([prep_text(t, question, tok) for t in texts])\n",
    "    # 2. extract the logits vector for the next possible token\n",
    "    outputs = model(input_ids.cuda())\n",
    "    logits,imp_logits = outputs[:2],outputs[2]\n",
    "    # 3. apply argmax to the logits so we have the probabilities of each index \n",
    "    (start_probs,starts),(end_probs,ends) = [torch.max(out, dim=1) for out in logits]\n",
    "    # 4. sort the sums of the starts and ends to determine which answers are the most ideal\n",
    "    sorted_sums = np.argsort([sp+ep for (sp,ep) in zip(start_probs,end_probs)])[::-1]\n",
    "    answerable = bool(torch.argmax(imp_logits,dim=1))\n",
    "    def _proc1(idx,start,end):\n",
    "        if start > end: return\n",
    "        elif start == end: end += 1\n",
    "        pred = tok.convert_ids_to_tokens(input_ids[idx][start:end])\n",
    "        return tok.convert_tokens_to_string(pred)\n",
    "    \n",
    "    # find the best answer\n",
    "    for i,s in enumerate(sorted_sums):\n",
    "        ans = _proc1(i,starts[i],ends[i])\n",
    "        if ans is not None and \"<pad>\" not in ans: return answerable, ans, texts[i]\n",
    "    return \"unanswerable\",texts[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-02T22:33:52.213Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tests with samples \n",
    "sample1 = \"[CLS] there have been thirty earthquakes in the past three days. [SEP] how many earthquakes have there been? [SEP]\"\n",
    "sample2 = \"[CLS] the storm took place yesterday from dawn to dusk [SEP] what took place??\"\n",
    "sample3 = \"[CLS] No.2 pencils are used a lot in schools. [SEP] what are used?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-02T22:33:52.215Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_pred([sample3],\"\",learn.model,tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
