{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ALBERT for Question Answering - SQuAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updates:\n",
    "\n",
    "Things implemented:\n",
    "- Data Loading\n",
    "- Model\n",
    "- Label Smoothing\n",
    "- Learner\n",
    "- Prediction on new data\n",
    "\n",
    "TODO:\n",
    "- Consider using the sliding window approach for long sequences\n",
    "- Use a more powerful machine to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:17.087618Z",
     "start_time": "2020-01-23T18:19:16.176376Z"
    }
   },
   "outputs": [],
   "source": [
    "from src import *\n",
    "from transformers import AutoTokenizer, AlbertForQuestionAnswering\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "import logging\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:17.093885Z",
     "start_time": "2020-01-23T18:19:17.089365Z"
    }
   },
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    data_path = Path(\"../data/SQuAD/1.1\"), # replace with the directory containing the parsed csv files\n",
    "    task = \"SQuAD\",\n",
    "    testing=False,\n",
    "    seed = 2020,\n",
    "    model = 'albert-base-v2',\n",
    "    max_lr=5e-5,\n",
    "    epochs=2,\n",
    "    use_fp16=False,\n",
    "    recreate_ds=False,\n",
    "    bs=4, \n",
    "    max_seq_len=384,\n",
    "    start_tok = \"[CLS]\",\n",
    "    end_tok = \"[SEP]\",\n",
    "    sep_tok = \"[SEP]\",\n",
    "    unk_tok_idx=1,\n",
    "    pad_idx=0,\n",
    "    feat_cols = [\"paragraph\",\"question\"],\n",
    "    label_cols = \"idxs\",\n",
    "    adjustment = 1,\n",
    ")\n",
    "\n",
    "config.model_name = re.findall(r\"(.+?)-\",config.model)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:17.107256Z",
     "start_time": "2020-01-23T18:19:17.095807Z"
    }
   },
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def remove_max_sl(df):\n",
    "    init_len = len(df)\n",
    "    df = df[df.seq_len < config.max_seq_len-2]\n",
    "    new_len = len(df)\n",
    "    print(f\"dropping {init_len - new_len} out of {init_len} questions\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:17.808887Z",
     "start_time": "2020-01-23T18:19:17.109008Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(config.data_path/f\"train_{config.model_name}.csv\")\n",
    "valid = pd.read_csv(config.data_path/f\"val_{config.model_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:17.850094Z",
     "start_time": "2020-01-23T18:19:17.810263Z"
    }
   },
   "outputs": [],
   "source": [
    "# randomizing the order of training data\n",
    "train = train.sample(frac=1,random_state = config.seed).reset_index(drop=True)\n",
    "valid = valid.sample(frac=1, random_state = config.seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:17.853831Z",
     "start_time": "2020-01-23T18:19:17.851403Z"
    }
   },
   "outputs": [],
   "source": [
    "# reduce df sizes if testing\n",
    "if config.testing:\n",
    "    train = train[:1000]\n",
    "    valid = valid[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:17.879760Z",
     "start_time": "2020-01-23T18:19:17.855198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping 998 out of 87599 questions\n",
      "dropping 643 out of 34726 questions\n"
     ]
    }
   ],
   "source": [
    "train, valid = remove_max_sl(train), remove_max_sl(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:17.891191Z",
     "start_time": "2020-01-23T18:19:17.881214Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>answer</th>\n",
       "      <th>idxs</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>About how many million square feet of office s...</td>\n",
       "      <td>Many of the world's largest media conglomerate...</td>\n",
       "      <td>['▁400']</td>\n",
       "      <td>[57, 58]</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On what date was George York executed?</td>\n",
       "      <td>The last use of the firing squad between 1608 ...</td>\n",
       "      <td>['▁june', '▁22', ',', '▁1965']</td>\n",
       "      <td>[59, 63]</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How did Wallace claim that patterns in the dis...</td>\n",
       "      <td>An 1855 paper on the \"introduction\" of species...</td>\n",
       "      <td>['▁if', '▁every', '▁new', '▁species', '▁always...</td>\n",
       "      <td>[34, 50]</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did Gaddafi's decisions in the oil industr...</td>\n",
       "      <td>With crude oil as the country's primary export...</td>\n",
       "      <td>['▁in', '▁1970', ',', '▁other', '▁op', 'ec', '...</td>\n",
       "      <td>[65, 87]</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What word describes an aortic valve with two r...</td>\n",
       "      <td>Schwarzenegger was born with a bicuspid aortic...</td>\n",
       "      <td>['▁b', 'icus', 'pid']</td>\n",
       "      <td>[7, 10]</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  About how many million square feet of office s...   \n",
       "1             On what date was George York executed?   \n",
       "2  How did Wallace claim that patterns in the dis...   \n",
       "3  How did Gaddafi's decisions in the oil industr...   \n",
       "4  What word describes an aortic valve with two r...   \n",
       "\n",
       "                                           paragraph  \\\n",
       "0  Many of the world's largest media conglomerate...   \n",
       "1  The last use of the firing squad between 1608 ...   \n",
       "2  An 1855 paper on the \"introduction\" of species...   \n",
       "3  With crude oil as the country's primary export...   \n",
       "4  Schwarzenegger was born with a bicuspid aortic...   \n",
       "\n",
       "                                              answer      idxs  seq_len  \n",
       "0                                           ['▁400']  [57, 58]       99  \n",
       "1                     ['▁june', '▁22', ',', '▁1965']  [59, 63]      147  \n",
       "2  ['▁if', '▁every', '▁new', '▁species', '▁always...  [34, 50]      237  \n",
       "3  ['▁in', '▁1970', ',', '▁other', '▁op', 'ec', '...  [65, 87]      149  \n",
       "4                              ['▁b', 'icus', 'pid']   [7, 10]      132  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:17.901784Z",
     "start_time": "2020-01-23T18:19:17.894195Z"
    }
   },
   "outputs": [],
   "source": [
    "class TokenizerProcessor(Processor):\n",
    "    def __init__(self, tok_func, max_sl, start_tok, end_tok, pre_rules=None,post_rules=None):\n",
    "        self.tok_func,self.max_sl = tok_func,max_sl\n",
    "        self.pre_rules,self.post_rules=pre_rules,post_rules\n",
    "        self.start_tok, self.end_tok = start_tok, end_tok\n",
    "\n",
    "    def proc1(self, x): return [self.start_tok] + self.tok_func(x)[:self.max_sl-2] + [self.end_tok]\n",
    "    \n",
    "    def __call__(self, items): return tqdm([self.proc1(x) for x in items])\n",
    "\n",
    "import collections\n",
    "class NumericalizeProcessor(Processor):\n",
    "    \"\"\"\n",
    "    only works with an existing vocab at the moment and min_freq is not accounted for\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab:dict, unk_tok_idx:int, min_freq=2): \n",
    "        self.vocab, self.unk_tok_idx, self.min_freq = vocab, unk_tok_idx, min_freq\n",
    "    \n",
    "    def proc1(self, x): return [self.vocab[i] if i in self.vocab else self.unk_tok_idx for i in x]\n",
    "    \n",
    "    def __call__(self, items): \n",
    "        if getattr(self, 'otoi', None) is None:\n",
    "            self.otoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.vocab)})\n",
    "        return tqdm([self.proc1(x) for x in items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:18.646976Z",
     "start_time": "2020-01-23T18:19:17.903653Z"
    }
   },
   "outputs": [],
   "source": [
    "tok = AutoTokenizer.from_pretrained(config.model)\n",
    "proc_tok = TokenizerProcessor(tok.tokenize, config.max_seq_len, config.start_tok, config.end_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:18.678100Z",
     "start_time": "2020-01-23T18:19:18.648432Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab = {tok.convert_ids_to_tokens(i):i for i in range(tok.vocab_size)}\n",
    "proc_num = NumericalizeProcessor(vocab, unk_tok_idx=config.unk_tok_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:18.689917Z",
     "start_time": "2020-01-23T18:19:18.679584Z"
    }
   },
   "outputs": [],
   "source": [
    "def str2tensor(s):\n",
    "    indices = re.findall(\"\\d+\",s)\n",
    "    return torch.tensor([int(indices[0]), int(indices[1])], dtype=torch.long)\n",
    "\n",
    "class QALabelProcessor(Processor):\n",
    "    def __init__(self, parse_func = noop, adjustment = 1):\n",
    "        self.parse_func = parse_func\n",
    "        self.adjustment = adjustment\n",
    "    def proc1(self, item): return self.parse_func(item) + self.adjustment\n",
    "    def __call__(self, items): return [self.proc1(item) for item in items]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:18.697130Z",
     "start_time": "2020-01-23T18:19:18.691080Z"
    }
   },
   "outputs": [],
   "source": [
    "proc_qa = QALabelProcessor(str2tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:18.703553Z",
     "start_time": "2020-01-23T18:19:18.698405Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextList(ItemList):      \n",
    "    @classmethod  \n",
    "    def from_df(cls, df, feat_cols, label_col, sep_tok, test=False):\n",
    "        feat_cols = listify(feat_cols)\n",
    "        x = df[feat_cols[0]]\n",
    "        for i in range(1,len(feat_cols)):\n",
    "            x += f\" {sep_tok} \" + df[feat_cols[i]]\n",
    "        labels = cls(df[label_col]) if not test else cls([0 for _ in len(df)])\n",
    "        return cls(x,labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:23.907910Z",
     "start_time": "2020-01-23T18:19:18.704895Z"
    }
   },
   "outputs": [],
   "source": [
    "if (not (config.data_path/\"squad_data_trn.pkl\").exists()) or config.recreate_ds:\n",
    "    il_train = TextList.from_df(train,config.feat_cols,config.label_cols,config.sep_tok)\n",
    "    il_valid = TextList.from_df(valid,config.feat_cols,config.label_cols,config.sep_tok)\n",
    "\n",
    "    ll_valid = LabeledData.label_by_func(sd.valid,label_story,proc_x = [proc_tok,proc_num], proc_y=[proc_tok,proc_num])\n",
    "\n",
    "    ll_train = LabeledData.label_by_func(sd.train,label_story,proc_x = [proc_tok,proc_num], proc_y=[proc_tok,proc_num])\n",
    "\n",
    "    # saving/loading presaved data\n",
    "\n",
    "    # save an object\n",
    "    pickle.dump(ll_train, open( config.data_path/\"squad_data_trn.pkl\", \"wb\" ) )\n",
    "    pickle.dump(ll_valid, open( config.data_path/\"squad_data_val.pkl\", \"wb\" ) )\n",
    "\n",
    "# load an object\n",
    "ll_train = pickle.load( open( config.data_path/\"squad_data_trn.pkl\", \"rb\" ) )\n",
    "ll_valid = pickle.load( open( config.data_path/\"squad_data_val.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:23.913193Z",
     "start_time": "2020-01-23T18:19:23.909255Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Sampler\n",
    "\n",
    "class SortSampler(Sampler):\n",
    "    def __init__(self, data_source, key): self.data_source,self.key = data_source,key\n",
    "    def __len__(self): return len(self.data_source)\n",
    "    def __iter__(self):\n",
    "        return iter(sorted(list(range(len(self.data_source))), key=self.key, reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:23.935217Z",
     "start_time": "2020-01-23T18:19:23.914489Z"
    }
   },
   "outputs": [],
   "source": [
    "class SortishSampler(Sampler):\n",
    "    def __init__(self, data_source, key, bs):\n",
    "        self.data_source,self.key,self.bs = data_source,key,bs\n",
    "\n",
    "    def __len__(self) -> int: return len(self.data_source)\n",
    "\n",
    "    def __iter__(self):\n",
    "        idxs = torch.randperm(len(self.data_source))\n",
    "        megabatches = [idxs[i:i+self.bs*50] for i in range(0, len(idxs), self.bs*50)]\n",
    "        sorted_idx = torch.cat([tensor(sorted(s, key=self.key, reverse=True)) for s in megabatches])\n",
    "        batches = [sorted_idx[i:i+self.bs] for i in range(0, len(sorted_idx), self.bs)]\n",
    "        max_idx = torch.argmax(tensor([self.key(ck[0]) for ck in batches]))  # find the chunk with the largest key,\n",
    "        batches[0],batches[max_idx] = batches[max_idx],batches[0]            # then make sure it goes first.\n",
    "        batch_idxs = torch.randperm(len(batches)-2)\n",
    "        sorted_idx = torch.cat([batches[i+1] for i in batch_idxs]) if len(batches) > 1 else LongTensor([])\n",
    "        sorted_idx = torch.cat([batches[0], sorted_idx, batches[-1]])\n",
    "        return iter(sorted_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:23.944689Z",
     "start_time": "2020-01-23T18:19:23.936421Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_collate_qa(samples, pad_idx=1, pad_first=False):\n",
    "    max_len = max([len(s[0]) for s in samples])\n",
    "    res = torch.zeros(len(samples), max_len).long() + pad_idx\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: res[i, -len(s[0]):] = torch.LongTensor(s[0])\n",
    "        else:         res[i, :len(s[0]) ] = torch.LongTensor(s[0])\n",
    "    return res, torch.cat([s[1].unsqueeze(0) for s in samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:23.954103Z",
     "start_time": "2020-01-23T18:19:23.945863Z"
    }
   },
   "outputs": [],
   "source": [
    "train_sampler = SortishSampler(ll_train.x, key=lambda t: len(ll_train[int(t)][0]), bs=config.bs)\n",
    "train_dl = DataLoader(ll_train, batch_size=config.bs, sampler=train_sampler, collate_fn=pad_collate_qa)\n",
    "\n",
    "valid_sampler = SortSampler(ll_valid.x, key=lambda t: len(ll_valid[int(t)][0]))\n",
    "valid_dl = DataLoader(ll_valid, batch_size=config.bs, sampler=valid_sampler, collate_fn=pad_collate_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:35.755575Z",
     "start_time": "2020-01-23T18:19:23.955260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 384])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter_dl = iter(train_dl)\n",
    "x,y = next(iter_dl); x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:35.758447Z",
     "start_time": "2020-01-23T18:19:35.756582Z"
    }
   },
   "outputs": [],
   "source": [
    "data = DataBunch(train_dl,valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:35.769996Z",
     "start_time": "2020-01-23T18:19:35.759647Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomAlbertModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomAlbertModel,self).__init__()\n",
    "        self.bert = AlbertForQuestionAnswering.from_pretrained(config.model)\n",
    "        self.bert.train()\n",
    "        \n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        outputs = self.bert(input_ids)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:35.775536Z",
     "start_time": "2020-01-23T18:19:35.771148Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining the loss function\n",
    "def cross_entropy_qa(input, target):\n",
    "    \"\"\"\n",
    "    Summing the cross entropy loss from the starting and ending indices. \n",
    "    \"\"\"\n",
    "    loss = torch.add(F.cross_entropy(input[0], target[:,0]) , F.cross_entropy(input[1], target[:,1]))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:35.781695Z",
     "start_time": "2020-01-23T18:19:35.776758Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining the evaluation metrics\n",
    "def acc_qa(input,target):\n",
    "    \"\"\"\n",
    "    Taking the average between the accuracies of predicting the start and ending indices\n",
    "    \"\"\"\n",
    "    return (accuracy(input[0], target[:,0]) + accuracy(input[1], target[:,1]))/2\n",
    "\n",
    "def exact_match(input,target):\n",
    "    def _acc(out, yb): return (torch.argmax(out, dim=1)==yb).float()\n",
    "    return (_acc(input[0], target[:,0]) + _acc(input[1], target[:,1]) == 2).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:35.790610Z",
     "start_time": "2020-01-23T18:19:35.782858Z"
    }
   },
   "outputs": [],
   "source": [
    "cbfs = [partial(AvgStatsCallback,[acc_qa,exact_match]),\n",
    "        CudaCallback,\n",
    "       ProgressCallback,\n",
    "       Recorder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:36.732223Z",
     "start_time": "2020-01-23T18:19:35.791749Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CustomAlbertModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:36.737967Z",
     "start_time": "2020-01-23T18:19:36.734260Z"
    }
   },
   "outputs": [],
   "source": [
    "def albert_splitter(m, g1=[],g2=[]):\n",
    "    if \"qa_outputs\" in list(dict(m.named_children()).keys()) :\n",
    "        g2+= m.qa_outputs.parameters()\n",
    "        pass\n",
    "    elif isinstance(m,torch.nn.modules.normalization.LayerNorm):\n",
    "        g2+= m.parameters()\n",
    "    elif hasattr(m, 'weight'): \n",
    "        g1+= m.parameters()\n",
    "    for ll in m.children(): albert_splitter(ll, g1, g2)\n",
    "    return g1,g2\n",
    "\n",
    "# test\n",
    "# [len(i) for i in albert_splitter(learn.model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:36.755509Z",
     "start_time": "2020-01-23T18:19:36.739129Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/fastai/course-v3/blob/master/nbs/dl2/11_train_imagenette.ipynb\n",
    "def create_phases(phases):\n",
    "    phases = listify(phases)\n",
    "    return phases + [1-sum(phases)]\n",
    "\n",
    "# https://github.com/fastai/course-v3/blob/master/nbs/dl2/11a_transfer_learning.ipynb\n",
    "def sched_1cycle(lrs, pct_start=0.3, mom_start=0.95, mom_mid=0.85, mom_end=0.95):\n",
    "    phases = create_phases(pct_start)\n",
    "    sched_lr  = [combine_scheds(phases, cos_1cycle_anneal(lr/10., lr, lr/1e5))\n",
    "                 for lr in lrs]\n",
    "    sched_mom = combine_scheds(phases, cos_1cycle_anneal(mom_start, mom_mid, mom_end))\n",
    "    return [ParamScheduler('lr', sched_lr),\n",
    "            ParamScheduler('mom', sched_mom)]\n",
    "\n",
    "disc_lr_sched = sched_1cycle([config.max_lr,1e-4], 0.3) # 3e-2 best with adam, 1e-3 for lamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:19:36.763669Z",
     "start_time": "2020-01-23T18:19:36.756591Z"
    }
   },
   "outputs": [],
   "source": [
    "# the learning rate we apply here does not matter since we are scheduling \n",
    "learn = Learner(model, data, cross_entropy_qa,lr=config.max_lr,cb_funcs=cbfs,splitter=albert_splitter,opt_func=lamb_opt())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-23T18:19:16.070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc_qa</th>\n",
       "      <th>train_exact_match</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_acc_qa</th>\n",
       "      <th>valid_exact_match</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='698' class='' max='21651', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      3.22% [698/21651 02:30<1:15:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1,cbs=disc_lr_sched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
