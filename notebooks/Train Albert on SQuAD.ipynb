{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ALBERT for Question Answering - SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T19:59:01.598705Z",
     "start_time": "2020-02-07T19:59:01.596235Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T19:59:01.610749Z",
     "start_time": "2020-02-07T19:59:01.602650Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T19:59:02.430380Z",
     "start_time": "2020-02-07T19:59:01.613136Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from transformers import AutoTokenizer,PretrainedConfig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "from src import *\n",
    "import fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T19:59:02.436720Z",
     "start_time": "2020-02-07T19:59:02.432017Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def load_dfs(config):\n",
    "    \"\"\"\n",
    "    - loads train and valid csv files, coverts them into dataframes\n",
    "    - truncates the dataset if testing\n",
    "    - drops those which exceed maximum allowed sequence length \n",
    "    \"\"\"\n",
    "    train = pd.read_csv(config.data_path+f\"/train_{config.squad_version}_{config.model_name}.csv\")\n",
    "    valid = pd.read_csv(config.data_path+f\"/val_{config.squad_version}_{config.model_name}.csv\")\n",
    "\n",
    "    train.drop_duplicates(inplace=True)\n",
    "    valid.drop_duplicates(inplace=True)\n",
    "\n",
    "    # randomizing the order of training data\n",
    "    train = train.sample(frac=1).reset_index(drop=True) #random_state = config.seed\n",
    "    valid = valid.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # reduce df sizes if testing\n",
    "    if config.testing:\n",
    "        train = train[:int(len(train)/config.data_reduction)]\n",
    "        valid = valid[:int(len(valid)/config.data_reduction)]\n",
    "\n",
    "    return remove_max_sl(train, config.max_seq_len), remove_max_sl(valid, config.max_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T19:59:02.454857Z",
     "start_time": "2020-02-07T19:59:02.438028Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def make_dataloaders(config, train_df, valid_df):\n",
    "    \"\"\"\n",
    "    - preprocesses raw text input into numericalized tensors \n",
    "    - creates train and valid dataloaders out of dataframes\n",
    "    \"\"\"\n",
    "    tok = AutoTokenizer.from_pretrained(config.model)\n",
    "    \n",
    "    proc_tok = QATokenizerProcessor(tok.tokenize, config.max_seq_len, config.start_tok, config.end_tok)\n",
    "\n",
    "    vocab = {tok.convert_ids_to_tokens(i):i for i in range(tok.vocab_size)}\n",
    "    proc_num = QANumericalizeProcessor(vocab, unk_tok_idx=config.unk_idx)\n",
    "    proc_qa = QALabelProcessor(str2tensor,config.adjustment)\n",
    "\n",
    "    if (not (os.path.exists(config.data_path+f\"/squad_{config.squad_version}_data_trn.pkl\"))) or config.recreate_ds or config.testing:\n",
    "        il_train = SquadTextList.from_df(train_df,config.feat_cols,config.label_cols,config.sep_tok)\n",
    "        il_valid = SquadTextList.from_df(valid_df,config.feat_cols,config.label_cols,config.sep_tok)\n",
    "\n",
    "        ll_valid = LabeledData(il_valid,il_valid.labels,proc_x = [proc_tok,proc_num], proc_y=[proc_qa])\n",
    "        ll_train = LabeledData(il_train,il_train.labels,proc_x = [proc_tok,proc_num], proc_y=[proc_qa])\n",
    "\n",
    "        # saving/loading presaved data if not testing\n",
    "        if not config.testing:\n",
    "            # save an object\n",
    "            pickle.dump(ll_train, open( config.data_path+f\"/squad_{config.squad_version}_data_trn.pkl\", \"wb\" ) )\n",
    "            pickle.dump(ll_valid, open( config.data_path+f\"/squad_{config.squad_version}_data_val.pkl\", \"wb\" ) )\n",
    "    else:\n",
    "        # load an object\n",
    "        ll_train = pickle.load( open( config.data_path+f\"/squad_{config.squad_version}_data_trn.pkl\", \"rb\" ) )\n",
    "        ll_valid = pickle.load( open( config.data_path+f\"/squad_{config.squad_version}_data_val.pkl\", \"rb\" ) )\n",
    "\n",
    "    collate_fn = partial(pad_collate_qa,pad_idx=config.pad_idx)\n",
    "    \n",
    "    train_sampler = SortishSampler(ll_train.x, key=lambda t: len(ll_train[int(t)][0]), bs=config.bs)\n",
    "    train_dl = DataLoader(ll_train, batch_size=config.bs, sampler=train_sampler, collate_fn=collate_fn)\n",
    "    \n",
    "    valid_sampler = SortSampler(ll_valid.x, key=lambda t: len(ll_valid[int(t)][0]))\n",
    "    valid_dl = DataLoader(ll_valid, batch_size=config.bs, sampler=valid_sampler, collate_fn=collate_fn)\n",
    "\n",
    "    return DataBunch(train_dl,valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model & Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T19:59:02.466453Z",
     "start_time": "2020-02-07T19:59:02.456170Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_learner(config, data, opt_func):\n",
    "    \"\"\"\n",
    "    - defines the model and relevant callbacks\n",
    "    - creates learner object used to train the model\n",
    "    \"\"\"\n",
    "    model_kwargs = {\"pretrained_model_name_or_path\": config.weights}\n",
    "    \n",
    "    if not config.load_checkpoint: model_kwargs[\"askai_config\"] = config\n",
    "    model = AlbertForQuestionAnsweringMTL.from_pretrained(**model_kwargs)\n",
    "\n",
    "    # setting up callbacks\n",
    "    cbfs = [partial(QAAvgStatsCallback,[acc_qa,acc_pos,exact_match,f1_score]),\n",
    "            ProgressCallback,\n",
    "            Recorder]\n",
    "    \n",
    "    if torch.cuda.is_available(): cbfs.append(CudaCallbackMTL)\n",
    "\n",
    "    if not config.testing and config.save_checkpoint:\n",
    "        cbfs.append(partial(SaveModelCallback,save_model_qa,config.output_dir,config.model,config.squad_version))\n",
    "\n",
    "    if config.effective_bs and config.bs != config.effective_bs:\n",
    "        cbfs.append(partial(GradientAccumulation,config.bs,config.effective_bs))\n",
    "\n",
    "    if config.stats_update_freq is not None: cbfs.append(partial(TrainStatsCallback,config.stats_update_freq))\n",
    "\n",
    "    learn = Learner(model, data, cross_entropy_qa_mtl_wtd,lr=config.max_lr,cb_funcs=cbfs,splitter=albert_splitter,\\\n",
    "                opt_func=opt_func)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T19:59:02.478000Z",
     "start_time": "2020-02-07T19:59:02.467637Z"
    }
   },
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    data_path = \"../data/SQuAD/2.0\", # replace with the directory containing the parsed csv files\n",
    "    output_dir = \"./models\", # for storing model weights between epochs\n",
    "    task = \"SQuAD\",\n",
    "    squad_version = \"2.0\",\n",
    "    testing=False,\n",
    "    data_reduction = 1000, # reduce df sizes by this amount while testing \n",
    "    seed = 2020,\n",
    "    model = \"albert-base-v2\",\n",
    "    max_lr=3e-5,\n",
    "    max_lr_last = 5e-5,\n",
    "    phases = .3,\n",
    "    optimizer=\"lamb\", # choose between 'adam' or 'lamb'\n",
    "    epochs=1,\n",
    "    use_fp16=False,\n",
    "    recreate_ds=False,\n",
    "    bs=4, \n",
    "    effective_bs=4, # set this different from bs to determine gradient accumulation steps (i.e. effective_bs/bs)\n",
    "    max_seq_len=512,\n",
    "    start_tok = \"[CLS]\",\n",
    "    end_tok = \"[SEP]\",\n",
    "    sep_tok = \"[SEP]\",\n",
    "    unk_idx=1,\n",
    "    sep_idx=3,\n",
    "    pad_idx=0,\n",
    "    feat_cols = [\"question\",\"paragraph\"],\n",
    "    label_cols = [\"idxs\",\"is_impossible\"],\n",
    "    adjustment = 2,\n",
    "    save_checkpoint = True,\n",
    "    load_checkpoint=None,#\"2020-02-07_14_58_00.025453-albert-base-v2-acc-0.61-ep-0-squad_2.0\",\n",
    "    num_labels_clas = 2,\n",
    "    clas_dropout_prob = .1,\n",
    "    stats_update_freq = .05,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T19:59:02.489863Z",
     "start_time": "2020-02-07T19:59:02.479218Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def main(config, return_learner=False):\n",
    "    \"\"\"\n",
    "    - loads data\n",
    "    - sets the Learning Rate and Momentum Scheduler \n",
    "    - defines the optimizer\n",
    "    - trains and outputs results periodically \n",
    "    \"\"\"\n",
    "    if isinstance(config, str): config = Config(**json.load(open(config,\"r\")))\n",
    "    assert type(config) == Config, f\"config parameter type must be Config or a path to a json file\"\n",
    "    if config.effective_bs: \n",
    "        assert config.effective_bs >= config.bs, f\"mini bs ({config.bs}) cannot be smaller than effective bs ({config.effective_bs})\"\n",
    "        assert config.effective_bs % config.bs == 0, \"mini bs ({config.bs}) should be a factor of the effective bs ({config.effective_bs})\"\n",
    "    \n",
    "    config.model_name=re.findall(r\"(.+?)-\",config.model)[0]\n",
    "    config.weights=config.output_dir+f\"/{config.load_checkpoint}\" if config.load_checkpoint else config.model\n",
    "\n",
    "    train,valid = load_dfs(config)\n",
    "    data = make_dataloaders(config, train, valid)\n",
    "\n",
    "    # set LR scheduler\n",
    "    disc_lr_sched = sched_1cycle([config.max_lr,config.max_lr_last], config.phases)\n",
    "\n",
    "    # set optimizer\n",
    "    assert config.optimizer.lower() in [\"adam\",\"lamb\"], f\"invalid optimizer in config {config.optimizer}\"\n",
    "    opt_func = lamb_opt() if config.optimizer.lower() == \"lamb\" else adam_opt()\n",
    "\n",
    "    learn = get_learner(config, data, opt_func)\n",
    "    learn.fit(config.epochs)#,cbs=disc_lr_sched)\n",
    "    if return_learner: return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T01:07:06.996429Z",
     "start_time": "2020-02-07T22:28:44.479049Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-spiece.model from cache at /home/devkosal/.cache/torch/transformers/dd1588b85b6fdce1320e224d29ad062e97588e17326b9d05a0b29ee84b8f5f93.c81d4deb77aec08ce575b7a39a989a79dd54f321bfb82c2b54dd35f52f8182cf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping 216 out of 130294 questions which exceed max sequence length\n",
      "dropping 124 out of 16315 questions which exceed max sequence length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file ./models/2020-02-07_14_58_00.025453-albert-base-v2-acc-0.61-ep-0-squad_2.0/config.json\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"adjustment\": 2,\n",
      "  \"architectures\": [\n",
      "    \"AlbertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bs\": 4,\n",
      "  \"clas_dropout_prob\": 0.1,\n",
      "  \"data_path\": \"../data/SQuAD/2.0\",\n",
      "  \"data_reduction\": 1000,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"effective_bs\": 4,\n",
      "  \"embedding_size\": 128,\n",
      "  \"end_tok\": \"[SEP]\",\n",
      "  \"epochs\": 1,\n",
      "  \"feat_cols\": [\n",
      "    \"question\",\n",
      "    \"paragraph\"\n",
      "  ],\n",
      "  \"finetuning_task\": null,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu_new\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"label_cols\": [\n",
      "    \"idxs\",\n",
      "    \"is_impossible\"\n",
      "  ],\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"load_checkpoint\": null,\n",
      "  \"max_lr\": 3e-05,\n",
      "  \"max_lr_last\": 5e-05,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_seq_len\": 512,\n",
      "  \"model\": \"albert-base-v2\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_labels_clas\": 2,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"optimizer\": \"lamb\",\n",
      "  \"output_attentions\": false,\n",
      "  \"output_dir\": \"./models\",\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_idx\": 0,\n",
      "  \"phases\": 0.3,\n",
      "  \"pruned_heads\": {},\n",
      "  \"recreate_ds\": false,\n",
      "  \"save_checkpoint\": true,\n",
      "  \"seed\": 2020,\n",
      "  \"sep_idx\": 3,\n",
      "  \"sep_tok\": \"[SEP]\",\n",
      "  \"squad_version\": \"2.0\",\n",
      "  \"start_tok\": \"[CLS]\",\n",
      "  \"stats_update_freq\": 0.1,\n",
      "  \"task\": \"SQuAD\",\n",
      "  \"testing\": false,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"unk_idx\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"use_fp16\": false,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file ./models/2020-02-07_14_58_00.025453-albert-base-v2-acc-0.61-ep-0-squad_2.0/pytorch_model.bin\n",
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-config.json from cache at /home/devkosal/.cache/torch/transformers/0bbb1531ce82f042a813219ffeed7a1fa1f44cd8f78a652c47fc5311e0d40231.49ede2f5cbd21a453ab03ed1214f9068f024910f34b5023577f3d0068326f7b0\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"architectures\": [\n",
      "    \"AlbertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"finetuning_task\": null,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu_new\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-pytorch_model.bin from cache at /home/devkosal/.cache/torch/transformers/a175de1d3c60bba6e74bd034c02a34d909d9f36a0cf472b02301c8790ba44834.ab806923413c2af99835e13fdbb6014b24af86b0de8edc2d71ef5c646fc54f24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc_qa</th>\n",
       "      <th>train_acc_pos</th>\n",
       "      <th>train_exact_match</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_acc_qa</th>\n",
       "      <th>valid_acc_pos</th>\n",
       "      <th>valid_exact_match</th>\n",
       "      <th>valid_f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='27614' class='' max='32520', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      84.91% [27614/32520 2:08:03<22:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:epoch 0 stats for iter 1626 out of 32520 iters are : {'loss': 2.9555501902675276, 'acc_qa': tensor(0.7448, device='cuda:0'), 'acc_pos': tensor(0.8630, device='cuda:0'), 'exact_match': tensor(0.6221, device='cuda:0'), 'f1_score': 0.8193979983273446}\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "INFO:root:epoch 0 stats for iter 13008 out of 32520 iters are : {'loss': 3.008898670529674, 'acc_qa': tensor(0.7427, device='cuda:0'), 'acc_pos': tensor(0.8692, device='cuda:0'), 'exact_match': tensor(0.6234, device='cuda:0'), 'f1_score': 0.8211594657496761}\n",
      "INFO:root:epoch 0 stats for iter 14634 out of 32520 iters are : {'loss': 2.9967891020056032, 'acc_qa': tensor(0.7429, device='cuda:0'), 'acc_pos': tensor(0.8694, device='cuda:0'), 'exact_match': tensor(0.6238, device='cuda:0'), 'f1_score': 0.8211307401804138}\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "INFO:root:epoch 0 stats for iter 26016 out of 32520 iters are : {'loss': 2.986223622001845, 'acc_qa': tensor(0.7433, device='cuda:0'), 'acc_pos': tensor(0.8717, device='cuda:0'), 'exact_match': tensor(0.6236, device='cuda:0'), 'f1_score': 0.8219623431563238}\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn = main(config, True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T01:07:07.003581Z",
     "start_time": "2020-02-08T01:07:06.998273Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mERROR: \u001b[0mThe function received no value for the required argument: config\n",
      "Usage: ipykernel_launcher.py CONFIG <flags>\n",
      "  optional flags:        --return_learner\n",
      "\n",
      "For detailed information on this command, run:\n",
      "  ipykernel_launcher.py --help\n"
     ]
    },
    {
     "ename": "FireExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mFireExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devkosal/anaconda3/envs/fastai/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "if __name__ == \"__main__\":\n",
    "    fire.Fire(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T01:07:07.004905Z",
     "start_time": "2020-02-07T19:59:01.587Z"
    }
   },
   "outputs": [],
   "source": [
    "! python scripts/notebook2script.py  notebooks/\"Train Albert on SQuAD.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
